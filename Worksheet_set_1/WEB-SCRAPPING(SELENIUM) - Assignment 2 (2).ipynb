{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WEB-SCRAPPING(SELENIUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the web driver\n",
    "#driver=webdriver.Chrome(r\"C:\\Users\\kunal's\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aur we can call driver from \n",
    "#jupitor home just upload the application in jupitor home and then call from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”\n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using id function\n",
    "#search_job=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "#search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"85a92ad486ef716dcefdc2343755ffb1\", element=\"fff59e88-c0fd-4605-9f62-c5fcaaa549ed\")>"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#search_job.send_keys(\"Data Analyst\")\n",
    "search_job=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"85a92ad486ef716dcefdc2343755ffb1\", element=\"58140f25-acf7-4b5f-ab6f-dba3e5d5abfd\")>"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding element for job location bar\n",
    "search_loc=driver.find_element_by_xpath('//input[@name=\"location\"]')\n",
    "search_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click on xpath functiom\n",
    "search_btn=driver.find_element_by_xpath('//button[@class=\"btn\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create 4 empty list for titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets extract all the tags having the job-titles\n",
    "titles_tags=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst',\n",
       " 'Tcs Hiring For Senior Data Analyst (bfsi domain)',\n",
       " 'Business Data Analyst',\n",
       " 'Business Data Analyst',\n",
       " 'Business Data Analyst - Google Data Studio & SQL',\n",
       " 'Senior Data Analyst',\n",
       " 'Tcs Hiring For MDM (master data management) Data Analyst (bfsi domain)',\n",
       " 'Senior Data Analyst IDAM Services',\n",
       " 'Data Analyst/Sr.Data Engineer',\n",
       " 'SENIOR DATA ANALYST',\n",
       " 'Executive Data Analyst',\n",
       " 'Senior Data Analyst IN4',\n",
       " 'Analyst & Designer - Software - Data Analysis',\n",
       " 'Data Analyst - I/II',\n",
       " 'Systems and Data Analyst, Safety and Provisioning',\n",
       " 'Data Analyst',\n",
       " 'Business Data Analyst - MIS & Reporting',\n",
       " 'Sr Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst']"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now the text form the job title inside the text extracted above\n",
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "job_title=[]\n",
    "for i in titles_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we do same for the company name,salary,and expericed required\n",
    "Now we will extract al the html tags where we have the company names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_tags=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gaussian Networks Private Limited',\n",
       " 'Tata Consultancy Services Ltd.',\n",
       " 'Trigent Software',\n",
       " 'Trigent Software',\n",
       " 'AVE-Promagne',\n",
       " 'Virtusa Consulting Services Pvt Ltd',\n",
       " 'Tata Consultancy Services Ltd.',\n",
       " 'GlaxoSmithKline Pharmaceuticals Limited',\n",
       " 'SYREN TECHNOLOGIES PRIVATE LIMITED',\n",
       " 'McAfee Software (India) Pvt. Ltd',\n",
       " 'Gokaldas Exports Ltd',\n",
       " 'Walmart Labs',\n",
       " 'HyreFox Consultants Pvt Ltd',\n",
       " 'Philips India Limited',\n",
       " 'AECOM India Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'INTERTRUST GROUP',\n",
       " 'Empower Retirement',\n",
       " 'Flipkart',\n",
       " 'Flipkart']"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Companies_tags=[]\n",
    "for i in companies_tags:\n",
    "    Companies_tags.append(i.text)\n",
    "Companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "#loc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru, Mumbai (All Areas)\\n(WFH during Covid)',\n",
       " 'Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru\\n(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Mumbai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Loc_tags=[]\n",
    "for i in loc_tags:\n",
    "    Loc_tags.append(i.text)\n",
    "Loc_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract al the html tags where we have the Experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "#experience_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-5 Yrs',\n",
       " '6-11 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-8 Yrs',\n",
       " '8-12 Yrs',\n",
       " '6-11 Yrs',\n",
       " '4-8 Yrs',\n",
       " '4-9 Yrs',\n",
       " '6-8 Yrs',\n",
       " '0-3 Yrs',\n",
       " '8-10 Yrs',\n",
       " '5-7 Yrs',\n",
       " '3-6 Yrs',\n",
       " '2-7 Yrs',\n",
       " '1-4 Yrs',\n",
       " '3-8 Yrs',\n",
       " '5-8 Yrs',\n",
       " '2-3 Yrs',\n",
       " '3-8 Yrs']"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experience_tags=[]\n",
    "for i in experience_tags:\n",
    "    Experience_tags.append(i.text)\n",
    "Experience_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract al the html tags where we have the Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi salary\"]')\n",
    "#salary_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " '10,00,000 - 20,00,000 PA.',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed']"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Salary_tags=[]\n",
    "for i in salary_tags:\n",
    "    Salary_tags.append(i.text)\n",
    "Salary_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(Companies_tags),len(Loc_tags),len(Salary_tags),len(Experience_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets make the dataframe from the above data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Loc_tags</th>\n",
       "      <th>Companies_tags</th>\n",
       "      <th>Experience_tags</th>\n",
       "      <th>Salary_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Gaussian Networks Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tcs Hiring For Senior Data Analyst (bfsi domain)</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst - Google Data Studio &amp; SQL</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...</td>\n",
       "      <td>Virtusa Consulting Services Pvt Ltd</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tcs Hiring For MDM (master data management) Da...</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst IDAM Services</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst/Sr.Data Engineer</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>SYREN TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>10,00,000 - 20,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SENIOR DATA ANALYST</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>McAfee Software (India) Pvt. Ltd</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1   Tcs Hiring For Senior Data Analyst (bfsi domain)   \n",
       "2                              Business Data Analyst   \n",
       "3                              Business Data Analyst   \n",
       "4   Business Data Analyst - Google Data Studio & SQL   \n",
       "5                                Senior Data Analyst   \n",
       "6  Tcs Hiring For MDM (master data management) Da...   \n",
       "7                  Senior Data Analyst IDAM Services   \n",
       "8                      Data Analyst/Sr.Data Engineer   \n",
       "9                                SENIOR DATA ANALYST   \n",
       "\n",
       "                                            Loc_tags  \\\n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "1                       Chennai, Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...   \n",
       "6                       Chennai, Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                            Companies_tags Experience_tags  \\\n",
       "0        Gaussian Networks Private Limited         3-5 Yrs   \n",
       "1           Tata Consultancy Services Ltd.        6-11 Yrs   \n",
       "2                         Trigent Software        5-10 Yrs   \n",
       "3                         Trigent Software        5-10 Yrs   \n",
       "4                             AVE-Promagne         3-8 Yrs   \n",
       "5      Virtusa Consulting Services Pvt Ltd        8-12 Yrs   \n",
       "6           Tata Consultancy Services Ltd.        6-11 Yrs   \n",
       "7  GlaxoSmithKline Pharmaceuticals Limited         4-8 Yrs   \n",
       "8       SYREN TECHNOLOGIES PRIVATE LIMITED         4-9 Yrs   \n",
       "9         McAfee Software (India) Pvt. Ltd         6-8 Yrs   \n",
       "\n",
       "                 Salary_tags  \n",
       "0              Not disclosed  \n",
       "1              Not disclosed  \n",
       "2              Not disclosed  \n",
       "3              Not disclosed  \n",
       "4              Not disclosed  \n",
       "5              Not disclosed  \n",
       "6              Not disclosed  \n",
       "7              Not disclosed  \n",
       "8  10,00,000 - 20,00,000 PA.  \n",
       "9              Not disclosed  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Job_title']=job_title\n",
    "df['Loc_tags']=Loc_tags\n",
    "df['Companies_tags']=Companies_tags\n",
    "df['Experience_tags']=Experience_tags\n",
    "df['Salary_tags']=Salary_tags\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in \n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter \n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "\n",
    "Note-\n",
    "\n",
    "\n",
    "1. All of the above steps have to be done in code. No step is to be done \n",
    "manuall.\n",
    "\n",
    "\n",
    "2.2.Please note that you have to scrape full job description. For that you may have to \n",
    "open each job separately as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"85a92ad486ef716dcefdc2343755ffb1\", element=\"4849efd5-3192-4755-af33-1e7981f4e0b6\")>"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#search_job.send_keys(\"Data Analyst\")\n",
    "search_job=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"85a92ad486ef716dcefdc2343755ffb1\", element=\"d7182120-51cb-46af-a375-c9771f6d94e2\")>"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding element for job location bar\n",
    "search_loc=driver.find_element_by_xpath('//input[@name=\"location\"]')\n",
    "search_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click on xpath functiom\n",
    "search_btn=driver.find_element_by_xpath('//button[@class=\"btn\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create 4 empty list for titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets extract all the tags having the job-titles\n",
    "titles_tags=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "#titles_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hiring For Data Scientist',\n",
       " 'Lead Data Scientist BFSI',\n",
       " 'Associate Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - I / II',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Sr Data Scientist',\n",
       " 'Sr Data Scientist',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Senior Data Scientist IN4',\n",
       " 'Senior Data Scientist (Marketplace)',\n",
       " 'Hiring For Manager and Sr. Manager | Data Scientist',\n",
       " 'Requirement For Data Scientist - Mumbai & Bangalore',\n",
       " 'Data Scientist (Python & SQL)',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Data Scientist- Senior Business Analyst/Lead Analyst']"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now the text form the job title inside the text extracted above\n",
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "job_title=[]\n",
    "for i in titles_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we do same for the company name,salary,and expericed required\n",
    "Now we will extract al the html tags where we have the company names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_tags=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "#companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tata Consultancy Services Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Philips India Limited',\n",
       " 'Brillio',\n",
       " 'Sharechat',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Walmart Labs',\n",
       " 'Airbnb',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Happiest Minds Technologies Pvt.Ltd',\n",
       " 'Walmart Labs',\n",
       " 'Walmart Labs',\n",
       " 'Vision Beyond Resources India Private Limited',\n",
       " 'CRISIL LIMITED',\n",
       " 'AVE-Promagne',\n",
       " 'Wrackle Technologies Pvt Ltd',\n",
       " 'Evalueserve.com Pvt. Ltd']"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Companies_tags=[]\n",
    "for i in companies_tags:\n",
    "    Companies_tags.append(i.text)\n",
    "Companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "#loc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai, Bangalore/Bengaluru, Mumbai (All Areas)\\n(WFH during Covid)',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Noida, Mumbai, New Delhi, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Loc_tags=[]\n",
    "for i in loc_tags:\n",
    "    Loc_tags.append(i.text)\n",
    "Loc_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract al the html tags where we have the Experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "#experience_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-8 Yrs',\n",
       " '5-9 Yrs',\n",
       " '3-5 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-3 Yrs',\n",
       " '4-8 Yrs',\n",
       " '4-8 Yrs',\n",
       " '3-7 Yrs',\n",
       " '6-10 Yrs',\n",
       " '7-12 Yrs',\n",
       " '6-8 Yrs',\n",
       " '6-8 Yrs',\n",
       " '5-10 Yrs',\n",
       " '7-10 Yrs',\n",
       " '4-8 Yrs',\n",
       " '8-13 Yrs',\n",
       " '2-6 Yrs',\n",
       " '6-8 Yrs',\n",
       " '6-11 Yrs',\n",
       " '2-7 Yrs']"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experience_tags=[]\n",
    "for i in experience_tags:\n",
    "    Experience_tags.append(i.text)\n",
    "Experience_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract al the html tags where we have the Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi salary\"]')\n",
    "#salary_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " '20,00,000 - 35,00,000 PA.',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed']"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Salary_tags=[]\n",
    "for i in salary_tags:\n",
    "    Salary_tags.append(i.text)\n",
    "Salary_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(Companies_tags),len(Loc_tags),len(Salary_tags),len(Experience_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Loc_tags</th>\n",
       "      <th>Companies_tags</th>\n",
       "      <th>Experience_tags</th>\n",
       "      <th>Salary_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Area...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Scientist BFSI</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Brillio</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - I / II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Sharechat</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Job_title  \\\n",
       "0           Hiring For Data Scientist   \n",
       "1            Lead Data Scientist BFSI   \n",
       "2            Associate Data Scientist   \n",
       "3                      Data Scientist   \n",
       "4             Data Scientist - I / II   \n",
       "5                      Data Scientist   \n",
       "6                      Data Scientist   \n",
       "7  Data Scientist: Advanced Analytics   \n",
       "8               Senior Data Scientist   \n",
       "9               Senior Data Scientist   \n",
       "\n",
       "                                            Loc_tags  \\\n",
       "0  Chennai, Bangalore/Bengaluru, Mumbai (All Area...   \n",
       "1                                Bengaluru/Bangalore   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bengaluru/Bangalore   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                     Companies_tags Experience_tags    Salary_tags  \n",
       "0    Tata Consultancy Services Ltd.         3-8 Yrs  Not disclosed  \n",
       "1            IBM India Pvt. Limited         5-9 Yrs  Not disclosed  \n",
       "2             Philips India Limited         3-5 Yrs  Not disclosed  \n",
       "3                           Brillio         3-8 Yrs  Not disclosed  \n",
       "4                         Sharechat         2-3 Yrs  Not disclosed  \n",
       "5  Allegis Services India Pvt. Ltd.         4-8 Yrs  Not disclosed  \n",
       "6  Allegis Services India Pvt. Ltd.         4-8 Yrs  Not disclosed  \n",
       "7            IBM India Pvt. Limited         3-7 Yrs  Not disclosed  \n",
       "8                      Walmart Labs        6-10 Yrs  Not disclosed  \n",
       "9                            Airbnb        7-12 Yrs  Not disclosed  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Job_title']=job_title\n",
    "df['Loc_tags']=Loc_tags\n",
    "df['Companies_tags']=Companies_tags\n",
    "df['Experience_tags']=Experience_tags\n",
    "df['Salary_tags']=Salary_tags\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.Please note that you have to scrape full job description. For that you may have to open each job separately as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "#url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-hiring-for-data-scientist-tata-consultancy-services-chennai-bangalore-bengaluru-mumbai-all-areas-3-to-8-years-110921000464?src=jobsearchDesk&sid=16315433099957255&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-bfsi-ibm-india-pvt-limited-bengaluru-bangalore-5-to-9-years-070921901691?src=jobsearchDesk&sid=16315433099957255&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-associate-data-scientist-philips-india-limited-bangalore-bengaluru-3-to-5-years-060921501985?src=jobsearchDesk&sid=16315433099957255&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-brillio-technologies-pvt-ltd-bangalore-bengaluru-3-to-8-years-130921905402?src=jobsearchDesk&sid=16315433099957255&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-i-ii-sharechat-bangalore-bengaluru-2-to-3-years-130921500157?src=jobsearchDesk&sid=16315433099957255&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-allegis-services-india-pvt-ltd-bangalore-bengaluru-4-to-8-years-130921603395?src=jobsearchDesk&sid=16315433099957255&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-allegis-services-india-pvt-ltd-bangalore-bengaluru-4-to-8-years-130921003393?src=jobsearchDesk&sid=16315433099957255&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-advanced-analytics-ibm-india-pvt-limited-bengaluru-bangalore-3-to-7-years-070921901677?src=jobsearchDesk&sid=16315433099957255&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-walmart-labs-bangalore-bengaluru-6-to-10-years-090921501063?src=jobsearchDesk&sid=16315433099957255&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-airbnb-bangalore-bengaluru-7-to-12-years-080921500017?src=jobsearchDesk&sid=16315433099957255&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-ibm-india-pvt-limited-bengaluru-bangalore-6-to-8-years-010921906637?src=jobsearchDesk&sid=16315433099957255&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-sr-data-scientist-ibm-india-pvt-limited-bangalore-bengaluru-6-to-8-years-010921906105?src=jobsearchDesk&sid=16315433099957255&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-happiest-minds-technologies-pvt-ltd-bangalore-bengaluru-5-to-10-years-070921501517?src=jobsearchDesk&sid=16315433099957255&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-in4-walmart-labs-bangalore-bengaluru-7-to-10-years-090921501064?src=jobsearchDesk&sid=16315433099957255&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-marketplace-walmart-labs-bangalore-bengaluru-4-to-8-years-090921500549?src=jobsearchDesk&sid=16315433099957255&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-hiring-for-manager-and-sr-manager-data-scientist-vision-beyond-resources-india-private-limited-noida-mumbai-new-delhi-gurgaon-gurugram-bangalore-bengaluru-8-to-13-years-090921005986?src=jobsearchDesk&sid=16315433099957255&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-requirement-for-data-scientist-mumbai-bangalore-crisil-limited-bangalore-bengaluru-mumbai-all-areas-2-to-6-years-080921005523?src=jobsearchDesk&sid=16315433099957255&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-python-sql-ave-promagne-hyderabad-secunderabad-chennai-bangalore-bengaluru-6-to-8-years-060921904967?src=jobsearchDesk&sid=16315433099957255&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-machine-learning-data-mining-wrackle-technologies-pvt-ltd-bangalore-bengaluru-6-to-11-years-080221900886?src=jobsearchDesk&sid=16315433099957255&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-senior-business-analyst-lead-analyst-evalueserve-com-pvt-ltd-gurgaon-gurugram-bangalore-bengaluru-2-to-7-years-110821005065?src=jobsearchDesk&sid=16315433099957255&xp=20&px=1']"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Url=[]\n",
    "for i in url:\n",
    "    Url.append(i.get_attribute('href'))\n",
    "Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hiring For Data Scientist',\n",
       " 'Lead Data Scientist BFSI',\n",
       " 'Associate Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - I / II',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Sr Data Scientist',\n",
       " 'Sr Data Scientist',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Senior Data Scientist IN4',\n",
       " 'Senior Data Scientist (Marketplace)',\n",
       " 'Hiring For Manager and Sr. Manager | Data Scientist',\n",
       " 'Requirement For Data Scientist - Mumbai & Bangalore',\n",
       " 'Data Scientist (Python & SQL)',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Data Scientist- Senior Business Analyst/Lead Analyst']"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Search_discription=[]\n",
    "for i in url:\n",
    "    Search_discription.append(i.text)\n",
    "Search_discription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Experience_Required</th>\n",
       "      <th>Salary_tags</th>\n",
       "      <th>Job-Discription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Area...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Scientist BFSI</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Lead Data Scientist BFSI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Brillio</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - I / II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Sharechat</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Data Scientist - I / II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Job_title  \\\n",
       "0           Hiring For Data Scientist   \n",
       "1            Lead Data Scientist BFSI   \n",
       "2            Associate Data Scientist   \n",
       "3                      Data Scientist   \n",
       "4             Data Scientist - I / II   \n",
       "5                      Data Scientist   \n",
       "6                      Data Scientist   \n",
       "7  Data Scientist: Advanced Analytics   \n",
       "8               Senior Data Scientist   \n",
       "9               Senior Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Chennai, Bangalore/Bengaluru, Mumbai (All Area...   \n",
       "1                                Bengaluru/Bangalore   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bengaluru/Bangalore   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                          Companies Experience_Required    Salary_tags  \\\n",
       "0    Tata Consultancy Services Ltd.             3-8 Yrs  Not disclosed   \n",
       "1            IBM India Pvt. Limited             5-9 Yrs  Not disclosed   \n",
       "2             Philips India Limited             3-5 Yrs  Not disclosed   \n",
       "3                           Brillio             3-8 Yrs  Not disclosed   \n",
       "4                         Sharechat             2-3 Yrs  Not disclosed   \n",
       "5  Allegis Services India Pvt. Ltd.             4-8 Yrs  Not disclosed   \n",
       "6  Allegis Services India Pvt. Ltd.             4-8 Yrs  Not disclosed   \n",
       "7            IBM India Pvt. Limited             3-7 Yrs  Not disclosed   \n",
       "8                      Walmart Labs            6-10 Yrs  Not disclosed   \n",
       "9                            Airbnb            7-12 Yrs  Not disclosed   \n",
       "\n",
       "                      Job-Discription  \n",
       "0           Hiring For Data Scientist  \n",
       "1            Lead Data Scientist BFSI  \n",
       "2            Associate Data Scientist  \n",
       "3                      Data Scientist  \n",
       "4             Data Scientist - I / II  \n",
       "5                      Data Scientist  \n",
       "6                      Data Scientist  \n",
       "7  Data Scientist: Advanced Analytics  \n",
       "8               Senior Data Scientist  \n",
       "9               Senior Data Scientist  "
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Job_title']=job_title\n",
    "df['Location']=Loc_tags\n",
    "df['Companies']=Companies_tags\n",
    "df['Experience_Required']=Experience_tags\n",
    "df['Salary_tags']=Salary_tags\n",
    "df['Job-Discription']=Search_discription\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the \n",
    "webpage as shown below:\n",
    "    \n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the picture.\n",
    "\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done \n",
    "manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_job.send_keys(\"Data Analyst\")\n",
    "search_job=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "\n",
    "#do click on xpath functiom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys(\"Data Scientist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job location bar\n",
    "search_loc=driver.find_element_by_xpath('//input[@name=\"location\"]')\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_box=driver.find_element_by_xpath('//span[@class=\"ellipsis fleft\" and @title=\"Bangalore/Bengaluru\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_box.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"26ad329b27c25bdbcb7afa8f4849823b\", element=\"fa022a22-f287-4b47-8e46-5c4f19de49cc\")>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_box=driver.find_element_by_xpath('//span[@class=\"ellipsis fleft\" and @title=\"10-15 Lakhs\"]')\n",
    "salary_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_box.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets extract all the tags having the job-titles\n",
    "titles_tags=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Associate Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Sr Data Scientist',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'Senior Data Scientist IN4',\n",
       " 'Senior Data Scientist (Marketplace)',\n",
       " 'Requirement For Data Scientist - Mumbai & Bangalore',\n",
       " 'Data Scientist (Python & SQL)',\n",
       " 'Lead Data Scientist - Machine Learning/ Data Mining',\n",
       " 'Data Scientist- Senior Business Analyst/Lead Analyst',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist 3',\n",
       " 'Data scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now the text form the job title inside the text extracted above\n",
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "job_title=[]\n",
    "for i in titles_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we do same for the company name,salary,and expericed required\n",
    "Now we will extract al the html tags where we have the company names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_tags=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Philips India Limited',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Walmart Labs',\n",
       " 'Airbnb',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Happiest Minds Technologies Pvt.Ltd',\n",
       " 'Walmart Labs',\n",
       " 'Walmart Labs',\n",
       " 'CRISIL LIMITED',\n",
       " 'AVE-Promagne',\n",
       " 'Wrackle Technologies Pvt Ltd',\n",
       " 'Evalueserve.com Pvt. Ltd',\n",
       " 'Oracle India Pvt. Ltd.',\n",
       " 'IHS Markit',\n",
       " 'Schneider Electric India Pvt. Ltd.',\n",
       " 'Western Digital',\n",
       " 'Bloom Consulting Services, Inc.',\n",
       " 'Walmart Labs',\n",
       " 'PRESCIENCE DECISION SOLUTIONS PRIVATE LIMITED']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Companies_tags=[]\n",
    "for i in companies_tags:\n",
    "    Companies_tags.append(i.text)\n",
    "Companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Noida, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'United States (USA), Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru\\n(WFH during Covid)']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Loc_tags=[]\n",
    "for i in loc_tags:\n",
    "    Loc_tags.append(i.text)\n",
    "Loc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-5 Yrs',\n",
       " '4-8 Yrs',\n",
       " '4-8 Yrs',\n",
       " '6-10 Yrs',\n",
       " '7-12 Yrs',\n",
       " '6-8 Yrs',\n",
       " '5-10 Yrs',\n",
       " '7-10 Yrs',\n",
       " '4-8 Yrs',\n",
       " '2-6 Yrs',\n",
       " '6-8 Yrs',\n",
       " '6-11 Yrs',\n",
       " '2-7 Yrs',\n",
       " '5-9 Yrs',\n",
       " '3-6 Yrs',\n",
       " '7-12 Yrs',\n",
       " '6-9 Yrs',\n",
       " '5-8 Yrs',\n",
       " '4-8 Yrs',\n",
       " '5-10 Yrs']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experience_tags=[]\n",
    "for i in experience_tags:\n",
    "    Experience_tags.append(i.text)\n",
    "Experience_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi salary\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " '12,00,000 - 22,00,000 PA.',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Salary_tags=[]\n",
    "for i in salary_tags:\n",
    "    Salary_tags.append(i.text)\n",
    "Salary_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(Companies_tags),len(Loc_tags),len(Salary_tags),len(Experience_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Loc_tags</th>\n",
       "      <th>Companies_tags</th>\n",
       "      <th>Experience_tags</th>\n",
       "      <th>Salary_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Happiest Minds Technologies Pvt.Ltd</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist IN4</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist (Marketplace)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Requirement For Data Scientist - Mumbai &amp; Bang...</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>CRISIL LIMITED</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                           Associate Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3                              Senior Data Scientist   \n",
       "4                              Senior Data Scientist   \n",
       "5                                  Sr Data Scientist   \n",
       "6                              SENIOR DATA SCIENTIST   \n",
       "7                          Senior Data Scientist IN4   \n",
       "8                Senior Data Scientist (Marketplace)   \n",
       "9  Requirement For Data Scientist - Mumbai & Bang...   \n",
       "\n",
       "                                  Loc_tags  \\\n",
       "0                      Bangalore/Bengaluru   \n",
       "1                      Bangalore/Bengaluru   \n",
       "2                      Bangalore/Bengaluru   \n",
       "3                      Bangalore/Bengaluru   \n",
       "4                      Bangalore/Bengaluru   \n",
       "5                      Bangalore/Bengaluru   \n",
       "6                      Bangalore/Bengaluru   \n",
       "7                      Bangalore/Bengaluru   \n",
       "8                      Bangalore/Bengaluru   \n",
       "9  Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "\n",
       "                        Companies_tags Experience_tags    Salary_tags  \n",
       "0                Philips India Limited         3-5 Yrs  Not disclosed  \n",
       "1     Allegis Services India Pvt. Ltd.         4-8 Yrs  Not disclosed  \n",
       "2     Allegis Services India Pvt. Ltd.         4-8 Yrs  Not disclosed  \n",
       "3                         Walmart Labs        6-10 Yrs  Not disclosed  \n",
       "4                               Airbnb        7-12 Yrs  Not disclosed  \n",
       "5               IBM India Pvt. Limited         6-8 Yrs  Not disclosed  \n",
       "6  Happiest Minds Technologies Pvt.Ltd        5-10 Yrs  Not disclosed  \n",
       "7                         Walmart Labs        7-10 Yrs  Not disclosed  \n",
       "8                         Walmart Labs         4-8 Yrs  Not disclosed  \n",
       "9                       CRISIL LIMITED         2-6 Yrs  Not disclosed  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Job_title']=job_title\n",
    "df['Loc_tags']=Loc_tags\n",
    "df['Companies_tags']=Companies_tags\n",
    "df['Experience_tags']=Experience_tags\n",
    "df['Salary_tags']=Salary_tags\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist \n",
    "Designation in Noida location. You have to scrape company_name, No. of days \n",
    "ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” \n",
    "in “location” field.\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown \n",
    "page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done \n",
    "manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url='https://www.glassdoor.co.in/member/home/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ff672a71bcd38a45d3dc39edbb8c0e4f\", element=\"629775f3-4ac5-4e2e-a75b-91a90e6637ac\")>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#search_job.send_keys(\"Data Scientist\")\n",
    "search_job=driver.find_element_by_id('sc.keyword')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_loc.send_keys(\"Banglore\")\n",
    "job_loc=driver.find_element_by_id('sc.location')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "job_loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click on xpath functiom\n",
    "search_btn=driver.find_element_by_xpath('//span[@class=\"css-8zxfjs\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so lets extract all the tags having the job-titles\n",
    "titles_tags=driver.find_elements_by_xpath('//a[@class=\"jobLink job-search-key-1rd3saf eigr9kq1\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist (BE/ B-tech 4-6 yrs)',\n",
       " 'Data Scientist 2',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist Intern',\n",
       " 'Executive - Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Associate Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist: Artificial Intelligence',\n",
       " 'Data Scientist (Matlab and Python)',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist (min 1year DS exp) Immed Hire',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist 1',\n",
       " 'Data Scientist-CAI',\n",
       " 'Data Scientist (Geospatial)',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist 3',\n",
       " 'Data Scientist',\n",
       " 'Lead Data Scientist / Artificial Intelligence Scientist',\n",
       " 'Analytics Data Pipeline Development Intern',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now the text form the job title inside the text extracted above\n",
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "job_title=[]\n",
    "for i in titles_tags:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_tags=driver.find_elements_by_xpath('//div[@class=\"d-flex justify-content-between align-items-start\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Applied Materials Inc.',\n",
       " 'Amplify Analytix',\n",
       " 'CommerceIQ',\n",
       " 'PayPal',\n",
       " 'Elpis IT Solutions',\n",
       " 'Argoid',\n",
       " 'NielsenIQ',\n",
       " 'Patient Bond India Private Limited',\n",
       " 'Top Mentor',\n",
       " 'Reach52, Inc.',\n",
       " 'IBM',\n",
       " 'Mercedes-Benz Research and Development India Private Limited',\n",
       " 'Lenskart',\n",
       " 'HP',\n",
       " 'Argoid',\n",
       " 'GE Aviation',\n",
       " 'Zinier',\n",
       " 'Maersk',\n",
       " 'HDFC Bank',\n",
       " 'Yara',\n",
       " 'Myian pharma',\n",
       " 'Oracle',\n",
       " 'Slice',\n",
       " 'Excelledia Ventures',\n",
       " 'Emplay Inc',\n",
       " 'Deloitte',\n",
       " 'Ambee',\n",
       " 'GLOBAL TECHNOLOGIES',\n",
       " 'Airtel India',\n",
       " 'Research Infinite Solutions LLP']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Companies_tags=[]\n",
    "for i in companies_tags:\n",
    "    Companies_tags.append(i.text)\n",
    "Companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tags=driver.find_elements_by_xpath('//span[@class=\"css-1buaf54 pr-xxsm job-search-key-iii9i8 e1rrn5ka4\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore',\n",
       " 'Bangalore',\n",
       " '',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Vadodara',\n",
       " 'Chandigarh',\n",
       " 'Pune',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Farīdābād',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Cochin',\n",
       " 'Bhopal',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Hyderābād',\n",
       " 'Gurgaon',\n",
       " 'Mohali']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Loc_tags=[]\n",
    "for i in loc_tags:\n",
    "    Loc_tags.append(i.text)\n",
    "Loc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_tags=driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-17n8uzw\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '6d',\n",
       " '7d',\n",
       " '2d',\n",
       " '24h',\n",
       " '5d',\n",
       " '10d',\n",
       " '3d',\n",
       " '20d',\n",
       " '6d',\n",
       " '12d',\n",
       " '24h',\n",
       " '12d',\n",
       " '5d',\n",
       " '23d',\n",
       " '17d',\n",
       " '9d',\n",
       " '21d',\n",
       " '1d',\n",
       " '30d+',\n",
       " '24h',\n",
       " '6d',\n",
       " '7d',\n",
       " '30d+',\n",
       " '10d',\n",
       " '24d',\n",
       " '13d']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Post_tags=[]\n",
    "for i in post_tags:\n",
    "    Post_tags.append(i.text)\n",
    "\n",
    "Post_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(Companies_tags),len(Loc_tags),len(Post_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Loc_tags</th>\n",
       "      <th>Companies_tags</th>\n",
       "      <th>Post_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Applied Materials Inc.</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Amplify Analytix</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist (BE/ B-tech 4-6 yrs)</td>\n",
       "      <td></td>\n",
       "      <td>CommerceIQ</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist 2</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Elpis IT Solutions</td>\n",
       "      <td>6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Argoid</td>\n",
       "      <td>7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Executive - Data Scientist</td>\n",
       "      <td>Vadodara</td>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>Patient Bond India Private Limited</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Top Mentor</td>\n",
       "      <td>5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Reach52, Inc.</td>\n",
       "      <td>10d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>IBM</td>\n",
       "      <td>3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist (Matlab and Python)</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Mercedes-Benz Research and Development India P...</td>\n",
       "      <td>20d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Farīdābād</td>\n",
       "      <td>Lenskart</td>\n",
       "      <td>6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>HP</td>\n",
       "      <td>12d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist (min 1year DS exp) Immed Hire</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Argoid</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>GE Aviation</td>\n",
       "      <td>12d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Zinier</td>\n",
       "      <td>5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Scientist 1</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Maersk</td>\n",
       "      <td>23d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist-CAI</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>HDFC Bank</td>\n",
       "      <td>17d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Scientist (Geospatial)</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Yara</td>\n",
       "      <td>9d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Myian pharma</td>\n",
       "      <td>21d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Scientist 3</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Slice</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lead Data Scientist / Artificial Intelligence ...</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>Excelledia Ventures</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Analytics Data Pipeline Development Intern</td>\n",
       "      <td>Bhopal</td>\n",
       "      <td>Emplay Inc</td>\n",
       "      <td>6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Ambee</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderābād</td>\n",
       "      <td>GLOBAL TECHNOLOGIES</td>\n",
       "      <td>10d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Airtel India</td>\n",
       "      <td>24d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mohali</td>\n",
       "      <td>Research Infinite Solutions LLP</td>\n",
       "      <td>13d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_title    Loc_tags  \\\n",
       "0                                      Data Scientist   Bangalore   \n",
       "1                               Senior Data Scientist   Bangalore   \n",
       "2                 Data Scientist (BE/ B-tech 4-6 yrs)               \n",
       "3                                    Data Scientist 2   Bangalore   \n",
       "4                                      Data Scientist   Bangalore   \n",
       "5                               Data Scientist Intern   Bangalore   \n",
       "6                          Executive - Data Scientist    Vadodara   \n",
       "7                                      Data Scientist  Chandigarh   \n",
       "8                            Associate Data Scientist        Pune   \n",
       "9                                      Data Scientist   Bangalore   \n",
       "10            Data Scientist: Artificial Intelligence   Bangalore   \n",
       "11                 Data Scientist (Matlab and Python)   Bangalore   \n",
       "12                                     Data Scientist   Farīdābād   \n",
       "13                                     Data Scientist   Bangalore   \n",
       "14       Data Scientist (min 1year DS exp) Immed Hire   Bangalore   \n",
       "15                                     Data Scientist   Bangalore   \n",
       "16                                     Data Scientist   Bangalore   \n",
       "17                                   Data Scientist 1   Bangalore   \n",
       "18                                 Data Scientist-CAI   Bangalore   \n",
       "19                        Data Scientist (Geospatial)   Bangalore   \n",
       "20                                     Data Scientist   Bangalore   \n",
       "21                                   Data Scientist 3   Bangalore   \n",
       "22                                     Data Scientist   Bangalore   \n",
       "23  Lead Data Scientist / Artificial Intelligence ...      Cochin   \n",
       "24         Analytics Data Pipeline Development Intern      Bhopal   \n",
       "25                                     Data Scientist   Bangalore   \n",
       "26                                     Data Scientist   Bangalore   \n",
       "27                                     Data Scientist   Hyderābād   \n",
       "28                                     Data Scientist     Gurgaon   \n",
       "29                                     Data Scientist      Mohali   \n",
       "\n",
       "                                       Companies_tags Post_tags  \n",
       "0                              Applied Materials Inc.      30d+  \n",
       "1                                    Amplify Analytix      30d+  \n",
       "2                                          CommerceIQ      30d+  \n",
       "3                                              PayPal      30d+  \n",
       "4                                  Elpis IT Solutions        6d  \n",
       "5                                              Argoid        7d  \n",
       "6                                           NielsenIQ        2d  \n",
       "7                  Patient Bond India Private Limited       24h  \n",
       "8                                          Top Mentor        5d  \n",
       "9                                       Reach52, Inc.       10d  \n",
       "10                                                IBM        3d  \n",
       "11  Mercedes-Benz Research and Development India P...       20d  \n",
       "12                                           Lenskart        6d  \n",
       "13                                                 HP       12d  \n",
       "14                                             Argoid       24h  \n",
       "15                                        GE Aviation       12d  \n",
       "16                                             Zinier        5d  \n",
       "17                                             Maersk       23d  \n",
       "18                                          HDFC Bank       17d  \n",
       "19                                               Yara        9d  \n",
       "20                                       Myian pharma       21d  \n",
       "21                                             Oracle        1d  \n",
       "22                                              Slice      30d+  \n",
       "23                                Excelledia Ventures       24h  \n",
       "24                                         Emplay Inc        6d  \n",
       "25                                           Deloitte        7d  \n",
       "26                                              Ambee      30d+  \n",
       "27                                GLOBAL TECHNOLOGIES       10d  \n",
       "28                                       Airtel India       24d  \n",
       "29                    Research Infinite Solutions LLP       13d  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Job_title']=job_title\n",
    "df['Loc_tags']=Loc_tags\n",
    "df['Companies_tags']=Companies_tags\n",
    "df['Post_tags']=Post_tags \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation \n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page.\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company \n",
    "name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done bby coding only and not manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url='https://www.glassdoor.co.in/Salaries/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ff672a71bcd38a45d3dc39edbb8c0e4f\", element=\"02c7823e-e81f-447b-b333-dab34d957e00\")>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#search_job.send_keys(\"Data Scientist\")\n",
    "search_job=driver.find_element_by_xpath('//input[@class=\"keyword\"]')\n",
    "search_job\n",
    "\n",
    "#do click on xpath functiom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ff672a71bcd38a45d3dc39edbb8c0e4f\", element=\"71d84017-d606-40d2-b8be-5bfc26130bc3\")>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#search_job.send_keys(\"Noida\")\n",
    "loc_tags=driver.find_element_by_xpath('//input[@class=\"loc\" and @data-test=\"search-bar-location-input\"]')\n",
    "loc_tags\n",
    "\n",
    "#do click on xpath functiom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "loc_tags.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do click on xpath functiom\n",
    "search_btn=driver.find_element_by_xpath('//button[@class=\"gd-btn-mkt\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we scrap 4 thing\n",
    "#Company name\n",
    "#Number of salaries\n",
    "#Average salary\n",
    "#Min salary\n",
    "#Max Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_tags=driver.find_elements_by_xpath('//a[@class=\"css-f3vw95 e1aj7ssy3\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tata Consultancy Services',\n",
       " 'IBM',\n",
       " 'Accenture',\n",
       " 'Delhivery',\n",
       " 'Ericsson-Worldwide',\n",
       " 'UnitedHealth Group',\n",
       " 'Optum',\n",
       " 'Optum Global Solutions',\n",
       " 'Valiance Solutions',\n",
       " 'EXL Service',\n",
       " 'Cognizant Technology Solutions',\n",
       " 'ZS Associates',\n",
       " 'Nagarro',\n",
       " 'Innovaccer',\n",
       " 'OYO',\n",
       " 'dunnhumby',\n",
       " 'Amazon',\n",
       " 'Fresher',\n",
       " 'CARS24.com',\n",
       " 'Vidooly Media Tech']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Companies_tags=[]\n",
    "for i in companies_tags:\n",
    "    Companies_tags.append(i.text)\n",
    "Companies_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_salaries=driver.find_elements_by_xpath('//div[@class=\"col-12 col-lg-auto\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['22 salaries',\n",
       " '20 salaries',\n",
       " '15 salaries',\n",
       " '15 salaries',\n",
       " '14 salaries',\n",
       " '14 salaries',\n",
       " '11 salaries',\n",
       " '10 salaries',\n",
       " '10 salaries',\n",
       " '9 salaries',\n",
       " '8 salaries',\n",
       " '8 salaries',\n",
       " '8 salaries',\n",
       " '8 salaries',\n",
       " '7 salaries',\n",
       " '7 salaries',\n",
       " '6 salaries',\n",
       " '6 salaries',\n",
       " '6 salaries',\n",
       " '6 salaries']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Number_of_salaries=[]\n",
    "for i in number_of_salaries:\n",
    "    Number_of_salaries.append(i.text)\n",
    "Number_of_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "average_salaries=driver.find_elements_by_xpath('//div[@class=\"col-12 col-lg-4 px-lg-0 d-flex align-items-baseline\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹6,28,021 /yr',\n",
       " '₹9,08,246 /yr',\n",
       " '₹11,93,390 /yr',\n",
       " '₹12,49,716 /yr',\n",
       " '₹7,58,335 /yr',\n",
       " '₹12,80,000 /yr',\n",
       " '₹12,70,000 /yr',\n",
       " '₹14,55,430 /yr',\n",
       " '₹8,86,064 /yr',\n",
       " '₹11,10,000 /yr',\n",
       " '₹9,62,227 /yr',\n",
       " '₹11,71,868 /yr',\n",
       " '₹11,01,815 /yr',\n",
       " '₹12,40,275 /yr',\n",
       " '₹14,51,902 /yr',\n",
       " '₹11,30,374 /yr',\n",
       " '₹20,63,782 /yr',\n",
       " '₹61,566 /mo',\n",
       " '₹10,80,727 /yr',\n",
       " '₹35,040 /mo']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Average_salaries=[]\n",
    "for i in average_salaries:\n",
    "    Average_salaries.append(i.text.replace(\"\\n\",\"\"))\n",
    "Average_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries=driver.find_elements_by_xpath('//div[@class=\"d-flex mt-xxsm css-79elbk epuxyqn0\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹4L min--->max ₹13L',\n",
       " '₹1L min--->max ₹28L',\n",
       " '₹6L min--->max ₹23L',\n",
       " '₹5L min--->max ₹1Cr',\n",
       " '₹4L min--->max ₹17L',\n",
       " '₹8L min--->max ₹16L',\n",
       " '₹8L min--->max ₹20L',\n",
       " '₹10L min--->max ₹18L',\n",
       " '₹5L min--->max ₹15L',\n",
       " '₹6L min--->max ₹16L',\n",
       " '₹4L min--->max ₹13L',\n",
       " '₹2L min--->max ₹19L',\n",
       " '₹4L min--->max ₹21L',\n",
       " '₹6L min--->max ₹17L',\n",
       " '₹10L min--->max ₹21L',\n",
       " '₹8L min--->max ₹21L',\n",
       " '₹10L min--->max ₹30L',\n",
       " '₹25T min--->max ₹1L',\n",
       " '₹9L min--->max ₹15L',\n",
       " '₹12T min--->max ₹64T']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Salaries=[]\n",
    "for i in salaries:\n",
    "    Salaries.append(i.text.replace(\"\\n\",\" min--->max \"))\n",
    "Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Companies_tags</th>\n",
       "      <th>Number_of_salaries</th>\n",
       "      <th>Average_Salary</th>\n",
       "      <th>Min-Max(salary)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>22 salaries</td>\n",
       "      <td>₹6,28,021 /yr</td>\n",
       "      <td>₹4L min---&gt;max ₹13L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>20 salaries</td>\n",
       "      <td>₹9,08,246 /yr</td>\n",
       "      <td>₹1L min---&gt;max ₹28L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹11,93,390 /yr</td>\n",
       "      <td>₹6L min---&gt;max ₹23L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹12,49,716 /yr</td>\n",
       "      <td>₹5L min---&gt;max ₹1Cr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹7,58,335 /yr</td>\n",
       "      <td>₹4L min---&gt;max ₹17L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹12,80,000 /yr</td>\n",
       "      <td>₹8L min---&gt;max ₹16L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹12,70,000 /yr</td>\n",
       "      <td>₹8L min---&gt;max ₹20L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹14,55,430 /yr</td>\n",
       "      <td>₹10L min---&gt;max ₹18L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹8,86,064 /yr</td>\n",
       "      <td>₹5L min---&gt;max ₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹11,10,000 /yr</td>\n",
       "      <td>₹6L min---&gt;max ₹16L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹9,62,227 /yr</td>\n",
       "      <td>₹4L min---&gt;max ₹13L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹11,71,868 /yr</td>\n",
       "      <td>₹2L min---&gt;max ₹19L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nagarro</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹11,01,815 /yr</td>\n",
       "      <td>₹4L min---&gt;max ₹21L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹12,40,275 /yr</td>\n",
       "      <td>₹6L min---&gt;max ₹17L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OYO</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹14,51,902 /yr</td>\n",
       "      <td>₹10L min---&gt;max ₹21L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dunnhumby</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹11,30,374 /yr</td>\n",
       "      <td>₹8L min---&gt;max ₹21L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹20,63,782 /yr</td>\n",
       "      <td>₹10L min---&gt;max ₹30L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fresher</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹61,566 /mo</td>\n",
       "      <td>₹25T min---&gt;max ₹1L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CARS24.com</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹10,80,727 /yr</td>\n",
       "      <td>₹9L min---&gt;max ₹15L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Vidooly Media Tech</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹35,040 /mo</td>\n",
       "      <td>₹12T min---&gt;max ₹64T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Companies_tags Number_of_salaries  Average_Salary  \\\n",
       "0        Tata Consultancy Services        22 salaries   ₹6,28,021 /yr   \n",
       "1                              IBM        20 salaries   ₹9,08,246 /yr   \n",
       "2                        Accenture        15 salaries  ₹11,93,390 /yr   \n",
       "3                        Delhivery        15 salaries  ₹12,49,716 /yr   \n",
       "4               Ericsson-Worldwide        14 salaries   ₹7,58,335 /yr   \n",
       "5               UnitedHealth Group        14 salaries  ₹12,80,000 /yr   \n",
       "6                            Optum        11 salaries  ₹12,70,000 /yr   \n",
       "7           Optum Global Solutions        10 salaries  ₹14,55,430 /yr   \n",
       "8               Valiance Solutions        10 salaries   ₹8,86,064 /yr   \n",
       "9                      EXL Service         9 salaries  ₹11,10,000 /yr   \n",
       "10  Cognizant Technology Solutions         8 salaries   ₹9,62,227 /yr   \n",
       "11                   ZS Associates         8 salaries  ₹11,71,868 /yr   \n",
       "12                         Nagarro         8 salaries  ₹11,01,815 /yr   \n",
       "13                      Innovaccer         8 salaries  ₹12,40,275 /yr   \n",
       "14                             OYO         7 salaries  ₹14,51,902 /yr   \n",
       "15                       dunnhumby         7 salaries  ₹11,30,374 /yr   \n",
       "16                          Amazon         6 salaries  ₹20,63,782 /yr   \n",
       "17                         Fresher         6 salaries     ₹61,566 /mo   \n",
       "18                      CARS24.com         6 salaries  ₹10,80,727 /yr   \n",
       "19              Vidooly Media Tech         6 salaries     ₹35,040 /mo   \n",
       "\n",
       "         Min-Max(salary)  \n",
       "0    ₹4L min--->max ₹13L  \n",
       "1    ₹1L min--->max ₹28L  \n",
       "2    ₹6L min--->max ₹23L  \n",
       "3    ₹5L min--->max ₹1Cr  \n",
       "4    ₹4L min--->max ₹17L  \n",
       "5    ₹8L min--->max ₹16L  \n",
       "6    ₹8L min--->max ₹20L  \n",
       "7   ₹10L min--->max ₹18L  \n",
       "8    ₹5L min--->max ₹15L  \n",
       "9    ₹6L min--->max ₹16L  \n",
       "10   ₹4L min--->max ₹13L  \n",
       "11   ₹2L min--->max ₹19L  \n",
       "12   ₹4L min--->max ₹21L  \n",
       "13   ₹6L min--->max ₹17L  \n",
       "14  ₹10L min--->max ₹21L  \n",
       "15   ₹8L min--->max ₹21L  \n",
       "16  ₹10L min--->max ₹30L  \n",
       "17   ₹25T min--->max ₹1L  \n",
       "18   ₹9L min--->max ₹15L  \n",
       "19  ₹12T min--->max ₹64T  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Companies_tags']=Companies_tags\n",
    "df['Number_of_salaries']=Number_of_salaries\n",
    "df['Average_Salary']=Average_salaries\n",
    "df['Min-Max(salary)']=Salaries \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to \n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and \n",
    "more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page \n",
    "you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of \n",
    "the page , then click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"382d405630bd84628fdf7a16d577d4f9\", element=\"c173d188-20f1-4b07-9515-5fc8476ec8ae\")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "search_field=driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "search_field\n",
    "\n",
    "#do click on xpath functiom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"382d405630bd84628fdf7a16d577d4f9\", element=\"c7861c46-ed50-4e0b-8b6b-c6bcfdc1827d\")>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write on search bar\n",
    "search_field.send_keys(\"Sunglasses\")\n",
    "search_btn=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn\n",
    "\n",
    "#do click on xpath functiom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "#do click on xpath functiom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AISLIN',\n",
       " 'GANSTA',\n",
       " 'PIRASO',\n",
       " 'Elligator',\n",
       " 'kingsunglasses',\n",
       " 'SHAAH COLLECTIONS',\n",
       " 'Fastrack',\n",
       " 'ROYAL SON',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Silver Kartz',\n",
       " 'SUNBEE',\n",
       " 'ROYAL SON',\n",
       " 'DEIXELS',\n",
       " 'ROYAL SON',\n",
       " 'Rich Club',\n",
       " 'Singco India',\n",
       " 'NuVew',\n",
       " 'OCCARIO',\n",
       " 'PHENOMENAL',\n",
       " 'NuVew',\n",
       " 'Singco India',\n",
       " 'povty',\n",
       " 'GANSTA',\n",
       " 'AISLIN',\n",
       " 'New Specs',\n",
       " 'HIPPON',\n",
       " 'hipe',\n",
       " 'AISLIN',\n",
       " 'Singco',\n",
       " 'WROGN',\n",
       " 'AISLIN',\n",
       " 'AISLIN',\n",
       " 'Badfella',\n",
       " 'Cruze',\n",
       " 'IRUS by IDEE',\n",
       " 'NuVew',\n",
       " 'Fravy',\n",
       " 'elegante',\n",
       " 'Poloport',\n",
       " 'AISLIN']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand1=[]\n",
    "for i in brand:\n",
    "    Brand1.append(i.text)\n",
    "Brand1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "dis=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\" or @class=\"IRpwTa _2-ICcC\"]')\n",
    "#do click on xpath functiom\n",
    "print(len(dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UV Protection, Gradient Cat-eye Sunglasses (58)',\n",
       " 'UV Protection, Gradient Wayfarer Sunglasses (53)',\n",
       " 'UV Protection Aviator Sunglasses (54)',\n",
       " 'UV Protection Round Sunglasses (54)',\n",
       " 'Mirrored, UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection, Polarized, Mirrored Rectangular Sunglass...',\n",
       " 'UV Protection Wayfarer Sunglasses (56)',\n",
       " 'UV Protection Retro Square Sunglasses (49)',\n",
       " 'UV Protection Retro Square Sunglasses (Free Size)',\n",
       " 'UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection, Polarized, Mirrored Wayfarer Sunglasses ...',\n",
       " 'Polarized, UV Protection Round Sunglasses (49)',\n",
       " 'UV Protection Aviator, Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection Rectangular Sunglasses (58)',\n",
       " 'UV Protection, Mirrored, Gradient Round Sunglasses (51)',\n",
       " 'Mirrored, UV Protection, Riding Glasses, Others Wrap-ar...',\n",
       " 'UV Protection Aviator Sunglasses (58)',\n",
       " 'Others Round Sunglasses (52)',\n",
       " 'UV Protection Retro Square Sunglasses (Free Size)',\n",
       " 'UV Protection Cat-eye Sunglasses (60)',\n",
       " 'UV Protection Aviator Sunglasses (Free Size)',\n",
       " 'UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection, Night Vision, Riding Glasses Aviator Sun...',\n",
       " 'UV Protection, Gradient Round Sunglasses (58)',\n",
       " 'Mirrored, UV Protection, Riding Glasses, Others Round S...',\n",
       " 'UV Protection Wayfarer Sunglasses (55)',\n",
       " 'UV Protection, Gradient, Mirrored, Riding Glasses Aviat...',\n",
       " 'UV Protection, Gradient Wayfarer, Round Sunglasses (63)',\n",
       " 'Mirrored Aviator Sunglasses (53)',\n",
       " 'Mirrored Round Sunglasses (52)',\n",
       " 'UV Protection, Gradient Butterfly, Retro Square Sunglas...',\n",
       " 'UV Protection, Gradient Butterfly, Wayfarer Sunglasses ...',\n",
       " 'Polarized, UV Protection Retro Square Sunglasses (53)',\n",
       " 'UV Protection Aviator Sunglasses (Free Size)',\n",
       " 'Gradient Rectangular Sunglasses (56)',\n",
       " 'UV Protection Aviator Sunglasses (57)',\n",
       " 'UV Protection Retro Square Sunglasses (Free Size)',\n",
       " 'Mirrored Round Sunglasses (Free Size)',\n",
       " 'UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'UV Protection, Gradient Butterfly, Retro Square Sunglas...']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Dis1=[]\n",
    "for i in dis:\n",
    "    Dis1.append(i.text)\n",
    "Dis1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(Dis1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "price=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹485',\n",
       " '₹284',\n",
       " '₹237',\n",
       " '₹295',\n",
       " '₹284',\n",
       " '₹198',\n",
       " '₹369',\n",
       " '₹664',\n",
       " '₹499',\n",
       " '₹246',\n",
       " '₹265',\n",
       " '₹664',\n",
       " '₹202',\n",
       " '₹474',\n",
       " '₹215',\n",
       " '₹331',\n",
       " '₹202',\n",
       " '₹179',\n",
       " '₹399',\n",
       " '₹403',\n",
       " '₹334',\n",
       " '₹349',\n",
       " '₹295',\n",
       " '₹498',\n",
       " '₹299',\n",
       " '₹257',\n",
       " '₹209',\n",
       " '₹795',\n",
       " '₹239',\n",
       " '₹789',\n",
       " '₹498',\n",
       " '₹545',\n",
       " '₹269',\n",
       " '₹499',\n",
       " '₹329',\n",
       " '₹210',\n",
       " '₹299',\n",
       " '₹399',\n",
       " '₹314',\n",
       " '₹516']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Price1=[]\n",
    "for i in price:\n",
    "    Price1.append(i.text)\n",
    "Price1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(Price1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['68% off',\n",
       " '85% off',\n",
       " '85% off',\n",
       " '88% off',\n",
       " '89% off',\n",
       " '88% off',\n",
       " '58% off',\n",
       " '66% off',\n",
       " '77% off',\n",
       " '83% off',\n",
       " '73% off',\n",
       " '66% off',\n",
       " '83% off',\n",
       " '68% off',\n",
       " '73% off',\n",
       " '83% off',\n",
       " '74% off',\n",
       " '69% off',\n",
       " '80% off',\n",
       " '72% off',\n",
       " '72% off',\n",
       " '65% off',\n",
       " '85% off',\n",
       " '67% off',\n",
       " '81% off',\n",
       " '78% off',\n",
       " '79% off',\n",
       " '75% off',\n",
       " '76% off',\n",
       " '69% off',\n",
       " '67% off',\n",
       " '64% off',\n",
       " '73% off',\n",
       " '61% off',\n",
       " '71% off',\n",
       " '73% off',\n",
       " '80% off',\n",
       " '80% off',\n",
       " '82% off',\n",
       " '66% off']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "discount1=[]\n",
    "for i in discount:\n",
    "    discount1.append(i.text)\n",
    "discount1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(discount1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"382d405630bd84628fdf7a16d577d4f9\", element=\"cde65066-0681-4e13-8ad1-9d58ce722129\")>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets scrap item from next page as well for that we have to find the next pag link and click it\n",
    "nxt_page=driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "nxt_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxt_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PIRASO',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'kingsunglasses',\n",
       " 'AISLIN',\n",
       " 'SHAAH COLLECTIONS',\n",
       " 'ROYAL SON',\n",
       " 'PHENOMENAL',\n",
       " 'NuVew',\n",
       " 'GANSTA',\n",
       " 'Elligator',\n",
       " 'Singco India',\n",
       " 'AISLIN',\n",
       " 'SUNBEE',\n",
       " 'Silver Kartz',\n",
       " 'DEIXELS',\n",
       " 'AISLIN',\n",
       " 'hipe',\n",
       " 'Rich Club',\n",
       " 'NuVew',\n",
       " 'AISLIN',\n",
       " 'IRUS by IDEE',\n",
       " 'AISLIN',\n",
       " 'PIRASO',\n",
       " 'AISLIN',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fastrack',\n",
       " 'SHAAH COLLECTIONS',\n",
       " 'GANSTA',\n",
       " 'kingsunglasses',\n",
       " 'ROYAL SON',\n",
       " 'Elligator',\n",
       " 'GANSTA',\n",
       " 'Singco India',\n",
       " 'GANSTA',\n",
       " 'PHENOMENAL',\n",
       " 'GANSTA',\n",
       " 'hipe',\n",
       " 'SUNBEE',\n",
       " 'IRUS by IDEE',\n",
       " 'NuVew']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand2=[]\n",
    "for i in brand:\n",
    "    Brand2.append(i.text)\n",
    "Brand2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "#do click on xpath functiom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UV Protection Aviator Sunglasses (54)',\n",
       " 'UV Protection Retro Square Sunglasses (Free Size)',\n",
       " 'UV Protection Round Sunglasses (54)',\n",
       " 'UV Protection, Gradient Wayfarer, Clubmaster Sunglasses...',\n",
       " 'UV Protection, Polarized, Mirrored Rectangular Sunglass...',\n",
       " 'UV Protection Retro Square Sunglasses (58)',\n",
       " 'UV Protection, Mirrored Retro Square Sunglasses (53)',\n",
       " 'UV Protection, Mirrored Wayfarer, Rectangular Sunglasse...',\n",
       " 'UV Protection, Night Vision, Riding Glasses Aviator Sun...',\n",
       " 'UV Protection Round Sunglasses (55)',\n",
       " 'Riding Glasses, Others, UV Protection Wrap-around Sungl...',\n",
       " 'UV Protection, Gradient Butterfly, Wayfarer Sunglasses ...',\n",
       " 'UV Protection, Polarized, Mirrored Retro Square Sunglas...',\n",
       " 'UV Protection Oval Sunglasses (56)',\n",
       " 'Polarized, UV Protection, Riding Glasses Wayfarer Sungl...',\n",
       " 'UV Protection Oval Sunglasses (60)',\n",
       " 'UV Protection, Night Vision, Gradient, Mirrored Round, ...',\n",
       " 'UV Protection, Others Round Sunglasses (48)',\n",
       " 'UV Protection Sports Sunglasses (62)',\n",
       " 'UV Protection, Gradient Aviator Sunglasses (61)',\n",
       " 'Gradient Rectangular Sunglasses (53)',\n",
       " 'UV Protection, Gradient Cat-eye Sunglasses (61)',\n",
       " 'UV Protection Aviator Sunglasses (54)',\n",
       " 'UV Protection, Gradient Oval Sunglasses (58)',\n",
       " 'UV Protection, Gradient Round Sunglasses (Free Size)',\n",
       " 'UV Protection Aviator Sunglasses (Free Size)',\n",
       " 'UV Protection Round Sunglasses (Free Size)',\n",
       " 'UV Protection Aviator Sunglasses (57)',\n",
       " 'Mirrored, UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'Polarized Rectangular Sunglasses (65)',\n",
       " 'Mirrored Round Sunglasses (53)',\n",
       " 'UV Protection, Mirrored Wayfarer Sunglasses (53)',\n",
       " 'UV Protection, Riding Glasses, Others Aviator, Wayfarer...',\n",
       " 'UV Protection, Gradient Aviator Sunglasses (55)',\n",
       " 'UV Protection Round Sunglasses (53)',\n",
       " 'UV Protection Aviator Sunglasses (57)',\n",
       " 'UV Protection, Night Vision, Riding Glasses, Gradient, ...',\n",
       " 'UV Protection, Polarized, Mirrored Wayfarer Sunglasses ...',\n",
       " 'Gradient Rectangular Sunglasses (53)',\n",
       " 'UV Protection, Mirrored, Gradient Wayfarer Sunglasses (...']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dis2=[]\n",
    "for i in dis:\n",
    "    Dis2.append(i.text)\n",
    "Dis2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(Dis2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "price=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹237',\n",
       " '₹499',\n",
       " '₹213',\n",
       " '₹525',\n",
       " '₹215',\n",
       " '₹474',\n",
       " '₹399',\n",
       " '₹375',\n",
       " '₹295',\n",
       " '₹266',\n",
       " '₹293',\n",
       " '₹545',\n",
       " '₹314',\n",
       " '₹284',\n",
       " '₹236',\n",
       " '₹725',\n",
       " '₹210',\n",
       " '₹299',\n",
       " '₹345',\n",
       " '₹625',\n",
       " '₹389',\n",
       " '₹498',\n",
       " '₹237',\n",
       " '₹498',\n",
       " '₹449',\n",
       " '₹520',\n",
       " '₹331',\n",
       " '₹230',\n",
       " '₹284',\n",
       " '₹664',\n",
       " '₹312',\n",
       " '₹221',\n",
       " '₹225',\n",
       " '₹289',\n",
       " '₹295',\n",
       " '₹374',\n",
       " '₹210',\n",
       " '₹284',\n",
       " '₹419',\n",
       " '₹398']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Price2=[]\n",
    "for i in price:\n",
    "    Price2.append(i.text)\n",
    "Price2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "discount=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['85% off',\n",
       " '77% off',\n",
       " '80% off',\n",
       " '65% off',\n",
       " '78% off',\n",
       " '68% off',\n",
       " '80% off',\n",
       " '64% off',\n",
       " '85% off',\n",
       " '86% off',\n",
       " '82% off',\n",
       " '64% off',\n",
       " '75% off',\n",
       " '76% off',\n",
       " '60% off',\n",
       " '70% off',\n",
       " '78% off',\n",
       " '62% off',\n",
       " '72% off',\n",
       " '70% off',\n",
       " '72% off',\n",
       " '70% off',\n",
       " '85% off',\n",
       " '67% off',\n",
       " '77% off',\n",
       " '34% off',\n",
       " '80% off',\n",
       " '78% off',\n",
       " '89% off',\n",
       " '66% off',\n",
       " '87% off',\n",
       " '77% off',\n",
       " '67% off',\n",
       " '85% off',\n",
       " '87% off',\n",
       " '81% off',\n",
       " '83% off',\n",
       " '71% off',\n",
       " '70% off',\n",
       " '74% off']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "discount2=[]\n",
    "for i in discount:\n",
    "    discount2.append(i.text)\n",
    "discount2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"382d405630bd84628fdf7a16d577d4f9\", element=\"4285ba9e-d861-4395-8652-12265c362f96\")>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets scrap item from next page as well for that we have to find the next pag link and click it\n",
    "nxt_page=driver.find_element_by_xpath('//a[@class=\"ge-49M _2Kfbh8\"]')\n",
    "nxt_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxt_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PIRASO',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'kingsunglasses',\n",
       " 'AISLIN',\n",
       " 'SHAAH COLLECTIONS',\n",
       " 'ROYAL SON',\n",
       " 'PHENOMENAL',\n",
       " 'NuVew',\n",
       " 'GANSTA',\n",
       " 'Elligator',\n",
       " 'Singco India',\n",
       " 'AISLIN',\n",
       " 'SUNBEE',\n",
       " 'Silver Kartz',\n",
       " 'DEIXELS',\n",
       " 'AISLIN',\n",
       " 'hipe',\n",
       " 'Rich Club',\n",
       " 'NuVew',\n",
       " 'AISLIN',\n",
       " 'IRUS by IDEE',\n",
       " 'AISLIN',\n",
       " 'PIRASO',\n",
       " 'AISLIN',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fastrack',\n",
       " 'SHAAH COLLECTIONS',\n",
       " 'GANSTA',\n",
       " 'kingsunglasses',\n",
       " 'ROYAL SON',\n",
       " 'Elligator',\n",
       " 'GANSTA',\n",
       " 'Singco India',\n",
       " 'GANSTA',\n",
       " 'PHENOMENAL',\n",
       " 'GANSTA',\n",
       " 'hipe',\n",
       " 'SUNBEE',\n",
       " 'IRUS by IDEE',\n",
       " 'NuVew']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand3=[]\n",
    "for i in brand:\n",
    "    Brand3.append(i.text)\n",
    "Brand3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UV Protection Aviator Sunglasses (54)',\n",
       " 'UV Protection Retro Square Sunglasses (Free Size)',\n",
       " 'UV Protection Round Sunglasses (54)',\n",
       " 'UV Protection, Gradient Wayfarer, Clubmaster Sunglasses...',\n",
       " 'UV Protection, Polarized, Mirrored Rectangular Sunglass...',\n",
       " 'UV Protection Retro Square Sunglasses (58)',\n",
       " 'UV Protection, Mirrored Retro Square Sunglasses (53)',\n",
       " 'UV Protection, Mirrored Wayfarer, Rectangular Sunglasse...',\n",
       " 'UV Protection, Night Vision, Riding Glasses Aviator Sun...',\n",
       " 'UV Protection Round Sunglasses (55)',\n",
       " 'Riding Glasses, Others, UV Protection Wrap-around Sungl...',\n",
       " 'UV Protection, Gradient Butterfly, Wayfarer Sunglasses ...',\n",
       " 'UV Protection, Polarized, Mirrored Retro Square Sunglas...',\n",
       " 'UV Protection Oval Sunglasses (56)',\n",
       " 'Polarized, UV Protection, Riding Glasses Wayfarer Sungl...',\n",
       " 'UV Protection Oval Sunglasses (60)',\n",
       " 'UV Protection, Night Vision, Gradient, Mirrored Round, ...',\n",
       " 'UV Protection, Others Round Sunglasses (48)',\n",
       " 'UV Protection Sports Sunglasses (62)',\n",
       " 'UV Protection, Gradient Aviator Sunglasses (61)',\n",
       " 'Gradient Rectangular Sunglasses (53)',\n",
       " 'UV Protection, Gradient Cat-eye Sunglasses (61)',\n",
       " 'UV Protection Aviator Sunglasses (54)',\n",
       " 'UV Protection, Gradient Oval Sunglasses (58)',\n",
       " 'UV Protection, Gradient Round Sunglasses (Free Size)',\n",
       " 'UV Protection Aviator Sunglasses (Free Size)',\n",
       " 'UV Protection Round Sunglasses (Free Size)',\n",
       " 'UV Protection Aviator Sunglasses (57)',\n",
       " 'Mirrored, UV Protection Wayfarer Sunglasses (Free Size)',\n",
       " 'Polarized Rectangular Sunglasses (65)',\n",
       " 'Mirrored Round Sunglasses (53)',\n",
       " 'UV Protection, Mirrored Wayfarer Sunglasses (53)',\n",
       " 'UV Protection, Riding Glasses, Others Aviator, Wayfarer...',\n",
       " 'UV Protection, Gradient Aviator Sunglasses (55)',\n",
       " 'UV Protection Round Sunglasses (53)',\n",
       " 'UV Protection Aviator Sunglasses (57)',\n",
       " 'UV Protection, Night Vision, Riding Glasses, Gradient, ...',\n",
       " 'UV Protection, Polarized, Mirrored Wayfarer Sunglasses ...',\n",
       " 'Gradient Rectangular Sunglasses (53)',\n",
       " 'UV Protection, Mirrored, Gradient Wayfarer Sunglasses (...']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dis3=[]\n",
    "for i in dis:\n",
    "    Dis3.append(i.text)\n",
    "Dis3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(Dis3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "price=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹237',\n",
       " '₹499',\n",
       " '₹213',\n",
       " '₹525',\n",
       " '₹215',\n",
       " '₹474',\n",
       " '₹399',\n",
       " '₹375',\n",
       " '₹295',\n",
       " '₹266',\n",
       " '₹293',\n",
       " '₹545',\n",
       " '₹314',\n",
       " '₹284',\n",
       " '₹236',\n",
       " '₹725',\n",
       " '₹210',\n",
       " '₹299',\n",
       " '₹345',\n",
       " '₹625',\n",
       " '₹389',\n",
       " '₹498',\n",
       " '₹237',\n",
       " '₹498',\n",
       " '₹449',\n",
       " '₹520',\n",
       " '₹331',\n",
       " '₹230',\n",
       " '₹284',\n",
       " '₹664',\n",
       " '₹312',\n",
       " '₹221',\n",
       " '₹225',\n",
       " '₹289',\n",
       " '₹295',\n",
       " '₹374',\n",
       " '₹210',\n",
       " '₹284',\n",
       " '₹419',\n",
       " '₹398']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "Price3=[]\n",
    "for i in price:\n",
    "    Price3.append(i.text)\n",
    "Price3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['85% off',\n",
       " '77% off',\n",
       " '80% off',\n",
       " '65% off',\n",
       " '78% off',\n",
       " '68% off',\n",
       " '80% off',\n",
       " '64% off',\n",
       " '85% off',\n",
       " '86% off',\n",
       " '82% off',\n",
       " '64% off',\n",
       " '75% off',\n",
       " '76% off',\n",
       " '60% off',\n",
       " '70% off',\n",
       " '78% off',\n",
       " '62% off',\n",
       " '72% off',\n",
       " '70% off',\n",
       " '72% off',\n",
       " '70% off',\n",
       " '85% off',\n",
       " '67% off',\n",
       " '77% off',\n",
       " '34% off',\n",
       " '80% off',\n",
       " '78% off',\n",
       " '89% off',\n",
       " '66% off',\n",
       " '87% off',\n",
       " '77% off',\n",
       " '67% off',\n",
       " '85% off',\n",
       " '87% off',\n",
       " '81% off',\n",
       " '83% off',\n",
       " '71% off',\n",
       " '70% off',\n",
       " '74% off']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we run the loop to iterate over the tags extracted above and extract the text inside them.\n",
    "\n",
    "discount3=[]\n",
    "for i in discount:\n",
    "    discount3.append(i.text)\n",
    "discount3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let combined all the scram data for making the count 100 and make a data frame.\n",
    "Brand=Brand1+Brand2+Brand3\n",
    "Discount=discount1+discount2+discount3\n",
    "Disc=Dis1+Dis2+Dis3\n",
    "Price=Price1+Price2+Price3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(len(Disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Discription</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Cat-eye Sunglasses (58)</td>\n",
       "      <td>₹485</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Gradient Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹284</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹237</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹284</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Oval Sunglasses (60)</td>\n",
       "      <td>₹725</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>hipe</td>\n",
       "      <td>UV Protection, Night Vision, Gradient, Mirrore...</td>\n",
       "      <td>₹210</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection, Others Round Sunglasses (48)</td>\n",
       "      <td>₹299</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Sports Sunglasses (62)</td>\n",
       "      <td>₹345</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Aviator Sunglasses (61)</td>\n",
       "      <td>₹625</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Discription Price  \\\n",
       "0           AISLIN    UV Protection, Gradient Cat-eye Sunglasses (58)  ₹485   \n",
       "1           GANSTA   UV Protection, Gradient Wayfarer Sunglasses (53)  ₹284   \n",
       "2           PIRASO              UV Protection Aviator Sunglasses (54)  ₹237   \n",
       "3        Elligator                UV Protection Round Sunglasses (54)  ₹295   \n",
       "4   kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹284   \n",
       "..             ...                                                ...   ...   \n",
       "95          AISLIN                 UV Protection Oval Sunglasses (60)  ₹725   \n",
       "96            hipe  UV Protection, Night Vision, Gradient, Mirrore...  ₹210   \n",
       "97       Rich Club        UV Protection, Others Round Sunglasses (48)  ₹299   \n",
       "98           NuVew               UV Protection Sports Sunglasses (62)  ₹345   \n",
       "99          AISLIN    UV Protection, Gradient Aviator Sunglasses (61)  ₹625   \n",
       "\n",
       "   Discount  \n",
       "0   68% off  \n",
       "1   85% off  \n",
       "2   85% off  \n",
       "3   88% off  \n",
       "4   89% off  \n",
       "..      ...  \n",
       "95  70% off  \n",
       "96  78% off  \n",
       "97  62% off  \n",
       "98  72% off  \n",
       "99  70% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Brand']=Brand\n",
    "df['Discription']=Disc\n",
    "df['Price']=Price\n",
    "df['Discount']= Discount\n",
    "\n",
    "df=df.head(100)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to \n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are \n",
    "1. Rating \n",
    "2. Review_summary \n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/apple-iphone-11-black-64-gb-includes%02earpods-power%02adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rating_review=driver.find_element_by_xpath('//div[@class=\"_3UAT2v _16PBlm\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rating_review.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '5', '5', '5', '5', '5', '5', '4', '5', '5']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rating1=[]\n",
    "for i in rating:\n",
    "    rating1.append(i.text)\n",
    "rating1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brilliant',\n",
       " 'Simply awesome',\n",
       " 'Best in the market!',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Worth every penny',\n",
       " 'Great product',\n",
       " 'Good choice',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "review1=[]\n",
    "for i in review:\n",
    "    review1.append(i.text)\n",
    "review1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_review=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Best Phone for the MoneyThe iPhone 11 offers superb cameras, a more durable design and excellent battery life for an affordable price.Compelling ultra-wide cameraNew Night mode is excellentLong battery life',\n",
       " 'Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.',\n",
       " 'Great iPhone very snappy experience as apple kind. Upgraded from iPhone 7.Pros-Camera top class- Battery top performed-Chipset no need to say as apple kind-Security as you expect from apple- Display super bright industry leading colouraccuracy and super responsive-Build quality as expect from apple sturdypremium durable beautiful stylish.-Os most stable os in smartphone industryCons-No 5G-Display is not based on OLED technology-Charger headphones and 1 apple stic...READ MORE',\n",
       " 'Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .',\n",
       " 'This is my first iOS phone. I am very happy with this product. Very much satisfied with this. I love this phone.',\n",
       " 'Previously I was using one plus 3t it was a great phoneAnd then I decided to upgrade I am stuck between Samsung s10 plus or iPhone 11I have seen the specs and everything were good except the display it’s somewhere between 720-1080 and it’s not even an amoled it’s an LCD displayBut I decided to go with iPhone because I have never used an IOS device I have Been an android user from the past 9 years I ordered IPhone 11 (128gb) product redMy experience after using 3 weeks1. The delivery ...READ MORE',\n",
       " 'Amazing Powerful and Durable Gadget.I’m am very happy with the camera picture quality, Amazing face id unlocked in dark room, Strong battery with perfect screen size as you can carry easily in pocket. This is my third iPhone.I shifted from android Samsung Note series to iPhone because of the strong build quality and peace of mind for next 3-4 years.Don’t think to much just go for it and I suggest you to go for minimum 128gb variant or more 256gb.I’ve attached my puppy pics and no fi...READ MORE',\n",
       " 'So far it’s been an AMAZING experience coming back to iOS after nearly a decade but it’s not as versatile as android though phone is sturdy dropped it accidentally a couple of times and nothing happened fortunately camera is awesome',\n",
       " 'i11 is worthy to buy, too much happy with the product. Thank u flipkart I received the item on time..loved it..',\n",
       " 'iphone 11 is a very good phone to buy only if you can compromise for the display. The display on this is device is pretty good but you can get other options with better displays in this price segment.If you can survive with an HD+ LCD panel with thicker bezels and a notch up top then this is a very good phone for you.Cameras are awesome, battery backup excellent, great performance and a decent premium look. Good job Apple !']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_review1=[]\n",
    "for i in full_review:\n",
    "    full_review1.append(i.text.replace(\"\\n\",\"\"))\n",
    "full_review1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(rating1),len(review1),len(full_review1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same from next page\n",
    "nxt=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[2]')\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '5', '5', '5', '5', '5', '5', '5', '5', '5']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "rating2=[]\n",
    "for i in rating:\n",
    "    rating2.append(i.text)\n",
    "rating2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Highly recommended',\n",
       " 'Perfect product!',\n",
       " 'Perfect product!',\n",
       " 'Classy product',\n",
       " 'Worth every penny',\n",
       " 'Highly recommended',\n",
       " 'Perfect product!',\n",
       " 'Simply awesome',\n",
       " 'Worth every penny',\n",
       " 'Terrific']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "review2=[]\n",
    "for i in review:\n",
    "    review2.append(i.text)\n",
    "review2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What a camera .....just awesome ..you can feel this iPhone just awesome . Good for gaming also ...try pubg in hd it’s just wow',\n",
       " 'It’s a must buy who is looking for an upgrade from previous generation of iPhones. If you are using XR then still you can hold on for sometime and upgrade to 2020 model else this phone is a must buy . Camera quality is amazing and wide angle is something to count upon. Performance wise it’s amazing and feels premium while holding in hand. So a big YES for this device. Go for 128 GB variant as the 4K videos will occupy lots of space and the storage can get over very quickly. Try to buy it with...READ MORE',\n",
       " 'Value for money❤️❤️Its awesome mobile phone in the world ...Display was very good and bright ..Trust me freinds you r never regret after Buying..Just go for it....I love this phone and i switch to iphone x to 11',\n",
       " 'Totally in love with this ❤ the camera quality is amazing just love it 😘😘😘 itsss dammnnnnnn amazing... Must buy iPhone 11 this is my best experience ever ☀👌👌🧡🧡🧡🧡🧡 thanku apple ❤',\n",
       " 'Best budget Iphone till date ❤️ go for it guys without second thought. Let me explain you guys about Camera, Display, battery, and performance.Camera: at this price range there is no comparison of camera, you’ll love the picture quality as well as video quality. I am a Vlogger I wanted an iPhone with 4k video by front camera and I got this phone and I am more than happy 😃Battery: I use this phone roughly as I am active social media person and I have a youtube channel. so the battery ba...READ MORE',\n",
       " \"It's my first time to use iOS phone and I am loving my upgradation 😍😍 I love the color, I love the assebility of the phone....I need to learn more about its functionality, but as far as I have seen, it's quite easy and it has a lot of functions to work on, specially if you are a content writer or a blogger you get a lot of content creation platforms and they are really amazing.This phone not only for good quality photography but a lot of other task too.😍💯\",\n",
       " \"Iphone is just awesome.. battery backup is very very nice.. continuously for 10 hours we can use it.camera is just awesome.. display is just fab.i love it alot..i had to wait 15 days for it as i pre ordered it..overalll it's worth the price..these all images are clicked by my iPhone..and i love it.\",\n",
       " 'Excellent camera, good performance, no lag. The lcd display is also good.. but difference come when we watch movie in prime and Netflix, the colours are not vibrant.. as we see in amoled display.. and the charger in box is of 5 watts.. takes more than 3 hours to charge from 0 to 100.. so guys be prepare to buy 18 watts charger . Finally I am an android user, it was my first Iapple phone, I promise u guys the iOS is so smooth.. overall the phone is damn good.... close eyes to buy it.. thanks t...READ MORE',\n",
       " 'It’s been almost a month since I have been using this phone. I upgraded from an iPhone 8. The main issue with my 8 was battery and this phone is just awesome when it comes to battery. It lasts a day and a half for me with my regular use , internet connected always with 4gCan’t move forward without saying this. Battery of this phone is a life saver when I am traveling or at work when I don’t get the option to chargeCamera is superb. Front cam selfies and back cam photos are just awesome....READ MORE',\n",
       " 'Really worth of money. i just love it. It is the best phone ever.']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_review=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "full_review2=[]\n",
    "for i in full_review:\n",
    "    full_review2.append(i.text.replace(\"\\n\",\"\"))\n",
    "full_review2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(rating2),len(review2),len(full_review2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same from next page\n",
    "#ge-49M _2Kfbh8\n",
    "nxt=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[4]')\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '5', '4', '5', '5', '5', '5', '4', '5', '5']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "rating3=[]\n",
    "for i in rating:\n",
    "    rating3.append(i.text)\n",
    "rating3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Worth every penny',\n",
       " 'Wonderful',\n",
       " 'Nice product',\n",
       " 'Perfect product!',\n",
       " 'Classy product',\n",
       " 'Brilliant',\n",
       " 'Must buy!',\n",
       " 'Good choice',\n",
       " 'Wonderful',\n",
       " 'Perfect product!']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "review3=[]\n",
    "for i in review:\n",
    "    review3.append(i.text)\n",
    "review3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Smooth like butter, camera like fantabulous, sound is crystal clear & its red color is damn attractive, i am just loving it. Must buy if you love photography.Lucky to get it in sale, thank you Flipkart.',\n",
       " 'This is my first ever I phone. Before this I was using my google nexus 5. But moving from android to iOS is a great experience. It’s worth at this price. I will highly recommend it if you want to move to iOS. The best part of this phone is it’s camera and it’s battery life. This two things have won my heart. I loved it. Happy to have it in my hand. Still exploring its features. And can’t forget to mention Flipkart service. Very prompt service and fast delivery.',\n",
       " 'Awesome Phone. Slightly high price but worth. Better than iPhone XR.Camera is superb and wide angle camera is very clear.12MP selfie camera is also very good.A13 Chip gives a very good and smooth performance.',\n",
       " 'Battery backup is extraordinary, camera is decent & performance offered by A13 bionic is awsome. The display is good in practical usage like the visibility of display is very good in direct sun light compare to pro models. Iam extremely satisfied for the money I spent.',\n",
       " 'Superb Product !!!A big and worthy upgrade from mi 3S to iphone 11 .Totally loved it !',\n",
       " 'I have migrated from OP 7pro... and trust me, iPhone 11 is totally worth it.. following are the reasons:-1)there is ABSOLUTELY NO ISSUE WITH THE DISPLAY... its crisp, sharp and I found it to be much much better than OP7 pro. Netflix, Prime video all run crisply... you won’t miss a thing. True Tone works flawlessly...the display brightness is perfect. OP have not calibrated their screens properly.2) iPhone 11 series have really good cameras... others have spoken in depth about them.3) bat...READ MORE',\n",
       " 'It’s an amazing product from apple and the camera is simply superb. Phone is faster.Night shot is simply superb and detailing and colour differentiation from camera is an added advantageThis review I have written from iPhone 11 only and I am glad to say outside.Cons wise if we see HD+ display only, no battery percentage indicator as in older iPhone 8.No assistive touch control button in itNo oleophobic coating on back panel glass and finger prints are visible but since I bought mint gr...READ MORE',\n",
       " 'Looking so good 👍 😍 super 👌 stylish 😎 phoneClean box 📦 good 👍 delivery 👌 fast deliveryOriginal box Original iphone 📱 👌 😍😍😍',\n",
       " 'I just directly switch from iphone 6s to iphone 11 .The best premium smartphone I recommend to everyone. Excellent quality and colors the iphone have in 11 series.Camera quality is just awesome and the major feel when we hold in our hands. The sound quality and volume is also higher then the previous models.I will recommend to buy iphone 11 instead of pro models , there is nothing much difference as this model contains everything which fulfill our needs.Only one thing that I dislike abo...READ MORE',\n",
       " 'After 1 month use I found camera quality best compared to my previous Samsung note 10+.Display not good as note 10 also charging too slow.Apple should add fast charger like 11 plus and pro.Best phone for daily use']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_review=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "full_review3=[]\n",
    "for i in full_review:\n",
    "    full_review3.append(i.text.replace(\"\\n\",\"\"))\n",
    "full_review3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(rating3),len(review3),len(full_review3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same from next page\n",
    "nxt=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '5', '5', '4', '5', '5', '5', '5', '5', '5']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "rating4=[]\n",
    "for i in rating:\n",
    "    rating4.append(i.text)\n",
    "rating4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Just wow!',\n",
       " 'Awesome',\n",
       " 'Terrific',\n",
       " 'Pretty good',\n",
       " 'Terrific purchase',\n",
       " 'Awesome',\n",
       " 'Classy product',\n",
       " 'Brilliant',\n",
       " 'Terrific',\n",
       " 'Perfect product!']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "review4=[]\n",
    "for i in review:\n",
    "    review4.append(i.text)\n",
    "review4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Best in class. Battery backup is good especially when you play games like Pubg COD. But it is sort of heavy when you hold in hands. Portrait mode is best to click pictures. Stage light effect is awesome. Try to click photos outside in nature because photos inside home or room will not give you the quality in any phone even in DSLR.',\n",
       " 'Very excited to have this phone. This phone has the real power unlike the android phones having SD 855 . The battery life is very good and the camera quality is excellent as comapred to redmi and other phones except google pixel. I M enjoying every single bit of it. Would recommed only if you have the budget.',\n",
       " \"I upgraded (downgraded?) from my iPhone X since the phone fell down and I didn't want to repair the screen. The box that the phone came in was super slim and I was worried that there'd be no 5W charger with it and my fears were confirmed. However, thankfully I had the 18W USB-C PD charger from Apple which I bought for my iPhone X and it worked perfectly. The charging time is as lethargic as ever though and it takes about 1:30 mins or even 2 hours depending on charge remaining. I'll list some ...READ MORE\",\n",
       " 'I was using Iphone 6s and also Oneplus 6t. Both mobiles were perfectly alright in Photos, gaming, and smooth interface . My 6s mobile getting battery issue. thought upgrade to 11. Really like this mobile of its Internal storage (compare to 6s) , camera and its touch feeling. Its a worth buying mobile for me.',\n",
       " 'Its Very awesome product working and good camera quality and all about best product and also flipkart is very great deal and offer nice price',\n",
       " 'I am using this phone for 5 days and its one of the best camera out there ❤️ the screen is not oled and i am coming from iphone xs so its little bit not up to the mark i would sayBut overall value for money💕😍the battery back up is far better than my iphone xs and its worth in my apple ecosystem💫❤️if u are an apple User and have the eco system then go for it❤️though i will be getting the new iphone but its pretty good💫',\n",
       " 'Best and amazing product.....phone looks so premium.... battary is also good as expected .... Wide angle camera is so addictive ...if you are a IOS lover....then this phone will be the best choice for you all!!💯🔥',\n",
       " 'Excellent camera and display touching very nice and smooth very improvement against iPhone XR and new processor is very fast',\n",
       " \"I got this beast today. And I must say the picture quality of its camera is awesome. Both the cameras works fine.As for as the processing is concerned, it runs without any lag. You can play and do whatever you want without a glitch.The battery runs for a day with medium and high workload.The display is good and the speakers are working fine.The earphones doesn't have any base and you can use it for calling mostly.The charging time is approximately for 90 minutes for full charging...READ MORE\",\n",
       " 'Awesome purchase. Amazing phone with good battery backup. It’s a top notch device. White colour looks amazing. Phone has a few extra feature than iPhone XR. Overall, this is value for money']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_review=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "full_review4=[]\n",
    "for i in full_review:\n",
    "    full_review4.append(i.text.replace(\"\\n\",\"\"))\n",
    "full_review4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(rating4),len(review4),len(full_review4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same from next page\n",
    "nxt=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[6]')\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '5', '5', '4', '5', '5', '5', '5', '5', '5']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "rating5=[]\n",
    "for i in rating:\n",
    "    rating5.append(i.text)\n",
    "rating5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Just wow!',\n",
       " 'Awesome',\n",
       " 'Terrific',\n",
       " 'Pretty good',\n",
       " 'Terrific purchase',\n",
       " 'Awesome',\n",
       " 'Classy product',\n",
       " 'Brilliant',\n",
       " 'Terrific',\n",
       " 'Perfect product!']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "review5=[]\n",
    "for i in review:\n",
    "    review5.append(i.text)\n",
    "review5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Best in class. Battery backup is good especially when you play games like Pubg COD. But it is sort of heavy when you hold in hands. Portrait mode is best to click pictures. Stage light effect is awesome. Try to click photos outside in nature because photos inside home or room will not give you the quality in any phone even in DSLR.',\n",
       " 'Very excited to have this phone. This phone has the real power unlike the android phones having SD 855 . The battery life is very good and the camera quality is excellent as comapred to redmi and other phones except google pixel. I M enjoying every single bit of it. Would recommed only if you have the budget.',\n",
       " \"I upgraded (downgraded?) from my iPhone X since the phone fell down and I didn't want to repair the screen. The box that the phone came in was super slim and I was worried that there'd be no 5W charger with it and my fears were confirmed. However, thankfully I had the 18W USB-C PD charger from Apple which I bought for my iPhone X and it worked perfectly. The charging time is as lethargic as ever though and it takes about 1:30 mins or even 2 hours depending on charge remaining. I'll list some ...READ MORE\",\n",
       " 'I was using Iphone 6s and also Oneplus 6t. Both mobiles were perfectly alright in Photos, gaming, and smooth interface . My 6s mobile getting battery issue. thought upgrade to 11. Really like this mobile of its Internal storage (compare to 6s) , camera and its touch feeling. Its a worth buying mobile for me.',\n",
       " 'Its Very awesome product working and good camera quality and all about best product and also flipkart is very great deal and offer nice price',\n",
       " 'I am using this phone for 5 days and its one of the best camera out there ❤️ the screen is not oled and i am coming from iphone xs so its little bit not up to the mark i would sayBut overall value for money💕😍the battery back up is far better than my iphone xs and its worth in my apple ecosystem💫❤️if u are an apple User and have the eco system then go for it❤️though i will be getting the new iphone but its pretty good💫',\n",
       " 'Best and amazing product.....phone looks so premium.... battary is also good as expected .... Wide angle camera is so addictive ...if you are a IOS lover....then this phone will be the best choice for you all!!💯🔥',\n",
       " 'Excellent camera and display touching very nice and smooth very improvement against iPhone XR and new processor is very fast',\n",
       " \"I got this beast today. And I must say the picture quality of its camera is awesome. Both the cameras works fine.As for as the processing is concerned, it runs without any lag. You can play and do whatever you want without a glitch.The battery runs for a day with medium and high workload.The display is good and the speakers are working fine.The earphones doesn't have any base and you can use it for calling mostly.The charging time is approximately for 90 minutes for full charging...READ MORE\",\n",
       " 'Awesome purchase. Amazing phone with good battery backup. It’s a top notch device. White colour looks amazing. Phone has a few extra feature than iPhone XR. Overall, this is value for money']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_review=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "full_review5=[]\n",
    "for i in full_review:\n",
    "    full_review5.append(i.text.replace(\"\\n\",\"\"))\n",
    "full_review5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(rating5),len(review5),len(full_review5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same from next page\n",
    "nxt=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '4', '5', '5', '3', '5', '5', '5', '5', '5']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "rating6=[]\n",
    "for i in rating:\n",
    "    rating6.append(i.text)\n",
    "rating6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Super!',\n",
       " 'Good choice',\n",
       " 'Simply awesome',\n",
       " 'Great product',\n",
       " 'Nice',\n",
       " 'Mind-blowing purchase',\n",
       " 'Worth every penny',\n",
       " 'Mind-blowing purchase',\n",
       " 'Awesome',\n",
       " 'Awesome']"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "review6=[]\n",
    "for i in review:\n",
    "    review6.append(i.text)\n",
    "review6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Everything good as expected from Apple, but only thing thing missing is the 18w power adapter, because if the phone is compatible for fast charging and it takes more than 3 hours for full charge on a normal charger then it should come bundled with the 18w adapter.',\n",
       " 'Great product as usual. Handy phone with best processor and camera quality in the market. Recommended 128GB storage 👍',\n",
       " 'excellent mobile phone with amazing feautures. 100% value for money.The greatest attribute was its battery(all day long usage). dont hesitate to buy. Only difference between 11pro and 11 is display and its telescope lens remaining all are same',\n",
       " 'Terrific!!! Lucky to get this phone in first lot. First switch over for me from android. awesome camera.. One of the best in class.. go for iphone 11 if you are the first time user.',\n",
       " 'Iphone 11 black 64gb is really a cool phone1. Camera is superb using it long time heats the phone a bit2. iOS 13 is elegant and nice3. Video yet to test4. Charger : Phone has the capability to fast charge but charger is not capable of doing it which frustrates being a top brand and providing and charger like this is worst from Apple5. Sound quality especially in headphones is wonderful',\n",
       " 'This is phone is super duper sexy.You will get in love with this phone the moment you will unbox it.Performance is awesome.So smooth, easy to handle.Sometimes, if working continuously, you will feel that the phone is heavy otherwise you won’t if worked for shorter period of time.I would personally suggest you to go for 128GB version because it will be a true value for money.Talking about colour, I find white colour as a royal one.',\n",
       " \"no complaint against the display it's very crisp , though it is not the OLED but if you put side by side and compare with iPhone xs you hardly notice any difference , i noticed the brightness because 11 has 600 nits compare to 1200 nits on xs . other wise you never feel that its a 720 p display. very very good quality LCD screen you can't compare with any other LCD screen it's far better than any other LCD screen available in market. battery is very impressive , and Love the sound of stereo s...READ MORE\",\n",
       " 'Wow!! What a beauty.. i was a hardcore fan of android and i always felt iphone is overrated. Features are far inferior to android and costs 4 times. I am a heavy user and for me battery life is one of the more important feature and everyone knows apple lacked in it. This is my 1st iphone and I am loving the change. RAM concept was totally misunderstood.. it is the most fluidic set I ever used. In hand feel is premium. Display is good but I loved the one plus more in this. Battery life is a sh...READ MORE',\n",
       " 'Features and design is good bt not satisfied with display i lyk apple bcz of their display quality bt in dis ph they give same diplay like other brands give us i hv 6s too frankly speaking both 6s and 11 have lcd display bt lots of diff between themApple previous lcd display was awsm bt nw jst making money like other brands vary disappointing it feels like m playing ios in samsung screen',\n",
       " 'So good look comfortable iPhone 11 I am so very happy my life first time iPhone used camera is 👌 sound quality is clear sounds']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_review=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "full_review6=[]\n",
    "for i in full_review:\n",
    "    full_review6.append(i.text.replace(\"\\n\",\"\"))\n",
    "full_review6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(rating6),len(review6),len(full_review6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same from next page\n",
    "nxt=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "rating7=[]\n",
    "for i in rating:\n",
    "    rating7.append(i.text)\n",
    "\n",
    "review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "review7=[]\n",
    "for i in review:\n",
    "    review7.append(i.text)\n",
    "\n",
    "full_review=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "full_review7=[]\n",
    "for i in full_review:\n",
    "    full_review7.append(i.text.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    " print(len(rating7),len(review7),len(full_review7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same from next page\n",
    "nxt=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[6]')\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "rating8=[]\n",
    "for i in rating:\n",
    "    rating8.append(i.text)\n",
    "\n",
    "review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "review8=[]\n",
    "for i in review:\n",
    "    review8.append(i.text)\n",
    "\n",
    "full_review=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "full_review8=[]\n",
    "for i in full_review:\n",
    "    full_review8.append(i.text.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    " print(len(rating8),len(review8),len(full_review8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same from next page\n",
    "nxt=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[5]')\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "rating9=[]\n",
    "for i in rating:\n",
    "    rating9.append(i.text)\n",
    "\n",
    "review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "review9=[]\n",
    "for i in review:\n",
    "    review9.append(i.text)\n",
    "\n",
    "full_review=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "full_review9=[]\n",
    "for i in full_review:\n",
    "    full_review9.append(i.text.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    " print(len(rating9),len(review9),len(full_review9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the same from next page\n",
    "nxt=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "nxt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "rating10=[]\n",
    "for i in rating:\n",
    "    rating10.append(i.text)\n",
    "\n",
    "review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "review10=[]\n",
    "for i in review:\n",
    "    review10.append(i.text)\n",
    "\n",
    "full_review=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "full_review10=[]\n",
    "for i in full_review:\n",
    "    full_review10.append(i.text.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    " print(len(rating10),len(review10),len(full_review10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets make data frame from all the 100 ratings,review and full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=rating1+rating2+rating3+rating4+rating5+rating6+rating7+rating8+rating9+rating10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "Review=review1+review2+review3+review4+review5+review6+review7+review8+review9+review10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_review=full_review1+full_review2+full_review3+full_review4+full_review5+full_review6+full_review7+full_review8+full_review9+full_review10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the MoneyThe iPhone 11 offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>This is phone is super duper sexy.You will get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>no complaint against the display it's very cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Wow!! What a beauty.. i was a hardcore fan of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Features and design is good bt not satisfied w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>So good look comfortable iPhone 11 I am so ver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                 Review  \\\n",
       "0       5              Brilliant   \n",
       "1       5         Simply awesome   \n",
       "2       5    Best in the market!   \n",
       "3       5       Perfect product!   \n",
       "4       5              Fabulous!   \n",
       "..    ...                    ...   \n",
       "95      5  Mind-blowing purchase   \n",
       "96      5      Worth every penny   \n",
       "97      5  Mind-blowing purchase   \n",
       "98      5                Awesome   \n",
       "99      5                Awesome   \n",
       "\n",
       "                                          Full_review  \n",
       "0   The Best Phone for the MoneyThe iPhone 11 offe...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  This is phone is super duper sexy.You will get...  \n",
       "96  no complaint against the display it's very cri...  \n",
       "97  Wow!! What a beauty.. i was a hardcore fan of ...  \n",
       "98  Features and design is good bt not satisfied w...  \n",
       "99  So good look comfortable iPhone 11 I am so ver...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Rating']=Rating\n",
    "df['Review']=Review\n",
    "df['Full_review']=Full_review\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and \n",
    "search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "Also note that all the steps required during scraping should be done through code \n",
    "only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver=webdriver.Chrome('chromedriver.exe')\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "rating=[]\n",
    "for i in rating:\n",
    "    rating10.append(i.text)\n",
    "\n",
    "review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "review10=[]\n",
    "for i in review:\n",
    "    review10.append(i.text)\n",
    "\n",
    "full_review=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "full_review10=[]\n",
    "for i in full_review:\n",
    "    full_review10.append(i.text.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"f18116127ffdc9ae3dcfab39b8dacf0a\", element=\"12511e53-33a9-40f9-99d5-a127eda5f268\")>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "search_field=driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "search_field\n",
    "\n",
    "#do click on xpath functiom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_field.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click()\n",
    "\n",
    "#do click on xpath functiom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_2WkVRV\n",
    "brand=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "brand1=[]\n",
    "for i in brand:\n",
    "    brand1.append(i.text)\n",
    "\n",
    "\n",
    "price=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "price1=[]\n",
    "for i in price:\n",
    "    price1.append(i.text)\n",
    "\n",
    "review=driver.find_elements_by_xpath('//a[@class=\"IRpwTa _2-ICcC\" or @class=\"IRpwTa\"]')\n",
    "review1=[]\n",
    "for i in review:\n",
    "    review1.append(i.text)\n",
    "\n",
    "dis=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "dis1=[]\n",
    "for i in dis:\n",
    "    dis1.append(i.text.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 40\n"
     ]
    }
   ],
   "source": [
    "print(len(brand1),len(review1),len(dis1),len(price1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxt=driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_2WkVRV\n",
    "brand=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "brand2=[]\n",
    "for i in brand:\n",
    "    brand2.append(i.text)\n",
    "\n",
    "\n",
    "price=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "price2=[]\n",
    "for i in price:\n",
    "    price2.append(i.text)\n",
    "\n",
    "review=driver.find_elements_by_xpath('//a[@class=\"IRpwTa _2-ICcC\" or @class=\"IRpwTa\"]')\n",
    "review2=[]\n",
    "for i in review:\n",
    "    review2.append(i.text)\n",
    "\n",
    "dis=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "dis2=[]\n",
    "for i in dis:\n",
    "    dis2.append(i.text.replace(\"\\n\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 40\n"
     ]
    }
   ],
   "source": [
    " print(len(brand2),len(review2),len(dis2),len(price2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxt=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[4]\")\n",
    "nxt.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40 40\n"
     ]
    }
   ],
   "source": [
    "#_2WkVRV\n",
    "brand=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "brand3=[]\n",
    "for i in brand:\n",
    "    brand3.append(i.text)\n",
    "\n",
    "\n",
    "price=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "price3=[]\n",
    "for i in price:\n",
    "    price3.append(i.text)\n",
    "\n",
    "review=driver.find_elements_by_xpath('//a[@class=\"IRpwTa _2-ICcC\" or @class=\"IRpwTa\"]')\n",
    "review3=[]\n",
    "for i in review:\n",
    "    review3.append(i.text)\n",
    "\n",
    "dis=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "dis3=[]\n",
    "for i in dis:\n",
    "    dis3.append(i.text.replace(\"\\n\",\"\"))\n",
    "print(len(brand2),len(review2),len(dis2),len(price2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=brand1+brand2+brand3\n",
    "Review=review1+review2+review3\n",
    "Discount=dis1+dis2+dis3\n",
    "Price=price1+price2+price3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>₹379</td>\n",
       "      <td>81% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India hub</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>₹356</td>\n",
       "      <td>64% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Longwalk</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "      <td>Men Boxer Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹474</td>\n",
       "      <td>86% off</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Echor</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "      <td>HHM Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>₹660</td>\n",
       "      <td>17% off</td>\n",
       "      <td>SM-607 Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>₹1,650</td>\n",
       "      <td>49% off</td>\n",
       "      <td>Brave IDP Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>mannu</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "      <td>Luxury Fashionable Breathable Casual Sneakers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Rebelbe</td>\n",
       "      <td>₹381</td>\n",
       "      <td>61% off</td>\n",
       "      <td>Casual Sneaker Sneakers For Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand   Price Discount  \\\n",
       "0   luxury fashion    ₹379  81% off   \n",
       "1        India hub    ₹399  80% off   \n",
       "2         Magnolia    ₹356  64% off   \n",
       "3         Longwalk    ₹236  52% off   \n",
       "4           BRUTON    ₹474  86% off   \n",
       "..             ...     ...      ...   \n",
       "95           Echor    ₹399  60% off   \n",
       "96           SPARX    ₹660  17% off   \n",
       "97            PUMA  ₹1,650  49% off   \n",
       "98           mannu    ₹398  60% off   \n",
       "99         Rebelbe    ₹381  61% off   \n",
       "\n",
       "                                               Review  \n",
       "0                                    Sneakers For Men  \n",
       "1                                    Sneakers For Men  \n",
       "2                                    Sneakers For Men  \n",
       "3                          Men Boxer Sneakers For Men  \n",
       "4   Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...  \n",
       "..                                                ...  \n",
       "95                               HHM Sneakers For Men  \n",
       "96                            SM-607 Sneakers For Men  \n",
       "97                         Brave IDP Sneakers For Men  \n",
       "98  Luxury Fashionable Breathable Casual Sneakers ...  \n",
       "99                    Casual Sneaker Sneakers For Men  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Brand']=Brand\n",
    "df['Price']=Price\n",
    "df['Discount']=Discount\n",
    "df['Review']=Review\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in \n",
    ".\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of \n",
    "the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "Please note that applying the filter and scraping the data , everything should be \n",
    "done through code only and there should not be any manual step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url='https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltr_price=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "fltr_price.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltr_black=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "fltr_black.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "brand=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "brand1=[]\n",
    "for i in brand:\n",
    "    brand1.append(i.text)\n",
    "\n",
    "\n",
    "price=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "price1=[]\n",
    "for i in price:\n",
    "    price1.append(i.text)\n",
    "\n",
    "\n",
    "review=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "\n",
    "review1=[]\n",
    "for i in review:\n",
    "    \n",
    "    review1.append(i.text)\n",
    "\n",
    "print(len(brand1),len(review1),len(price1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxtpage=driver.find_element_by_xpath('//*[@id=\"desktopSearchResults\"]/div[2]/section/div[2]/ul/li[3]/a')\n",
    "nxtpage.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "brand=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "brand2=[]\n",
    "for i in brand:\n",
    "    brand2.append(i.text)\n",
    "\n",
    "\n",
    "price=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "price2=[]\n",
    "for i in price:\n",
    "    price2.append(i.text)\n",
    "\n",
    "\n",
    "review=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "\n",
    "review2=[]\n",
    "for i in review:\n",
    "    \n",
    "    review2.append(i.text)\n",
    "\n",
    "print(len(brand2),len(review2),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxtpage=driver.find_element_by_xpath('//*[@id=\"desktopSearchResults\"]/div[2]/section/div[2]/ul/li[5]/a')\n",
    "nxtpage.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "brand=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "brand3=[]\n",
    "for i in brand:\n",
    "    brand3.append(i.text)\n",
    "\n",
    "\n",
    "price=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "price3=[]\n",
    "for i in price:\n",
    "    price3.append(i.text)\n",
    "\n",
    "\n",
    "review=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "\n",
    "review3=[]\n",
    "for i in review:\n",
    "    \n",
    "    review3.append(i.text)\n",
    "\n",
    "print(len(brand3),len(review3),len(price3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=brand1+brand2+brand3\n",
    "Review=review1+review2+review3\n",
    "Price=price1+price2+price3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Review</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men BlackTraining or Gym Shoes</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Cell Fraction Fade Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8099Rs. 8999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8999Rs. 9999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Monks</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 7192Rs. 8990(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes F1 Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Pacer Future Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Mirage Sport Trainers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                             Review  \\\n",
       "0                   Puma     Men BlackTraining or Gym Shoes   \n",
       "1                   Puma     Men Cell Fraction Fade Running   \n",
       "2                   Geox                 Men Solid Sneakers   \n",
       "3           Hush Puppies  Men Solid Leather Formal Slip-Ons   \n",
       "4           Hush Puppies  Men Solid Leather Formal Slip-Ons   \n",
       "..                   ...                                ...   \n",
       "95                 Ruosh     Men Solid Leather Formal Monks   \n",
       "96  Heel & Buckle London                Women Leather Pumps   \n",
       "97       PUMA Motorsport        Unisex Mercedes F1 Sneakers   \n",
       "98                  Puma       Unisex Pacer Future Sneakers   \n",
       "99                  Puma       Unisex Mirage Sport Trainers   \n",
       "\n",
       "                        Price  \n",
       "0                    Rs. 6999  \n",
       "1                    Rs. 6999  \n",
       "2                    Rs. 9999  \n",
       "3   Rs. 8099Rs. 8999(10% OFF)  \n",
       "4   Rs. 8999Rs. 9999(10% OFF)  \n",
       "..                        ...  \n",
       "95                   Rs. 8990  \n",
       "96  Rs. 7192Rs. 8990(20% OFF)  \n",
       "97                   Rs. 7999  \n",
       "98                   Rs. 6999  \n",
       "99                   Rs. 8999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Brand']=Brand\n",
    "df['Review']=Review\n",
    "df['Price']=Price\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/\n",
    " Enter “Laptop” in the search field and then click the search icon.\n",
    " Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the \n",
    "below image\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes \n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url='https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"a517b4b9e0d6533e3e13bef2e839816a\", element=\"317433e2-9169-411a-879f-86505ba9420f\")>"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_field=driver.find_element_by_xpath('//*[@id=\"twotabsearchtextbox\"]')\n",
    "search_field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn=driver.find_element_by_xpath('//*[@id=\"nav-search-submit-button\"]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltr_i7=driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/div/label/i')\n",
    "fltr_i7.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['HP Envy 11th Gen Core i7 Processor 13.3-inch (33.78 cms) FHD Touchscreen Laptop (16GB/1TB SSD/Win 10/NVIDIA MX450 2GB/Natural Silver/1.3 kg), 13-ba1018TX', 'ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FHD 144Hz, Intel Core i7-11370H 11th Gen, RTX 3050 Ti 4GB Graphics, Gaming Laptop (16GB/1TB SSD/Office 2019/Windows 10/Eclipse Gray/2 kg), FX516PE-HN088TS', 'Mi Notebook Horizon Edition 14 Intel Core i7-10510U 10th Gen Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg)(Without Webcam) XMA1904-AF', 'Lenovo IdeaPad S540 11th Gen Intel Core i7 13.3\" QHD IPS Thin & Light Laptop (16GB/512GB SSD/Windows 10/MS Office 2019/Intel Iris Xe Graphics/Iron Grey/1.28Kg), 82H1002CIN', 'ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms) FHD 144Hz, Intel Core i7-11370H 11th Gen, RTX 3050 4GB Graphics Gaming Laptop (16GB RAM/512GB SSD/Windows 10/White/2 kg), FX516PC-HN062T', 'HP Pavilion 13(2021) 11th Gen Intel Core i7 Laptop, 16GB RAM, 1TB SSD, 13.3-inch(33.8 cm) FHD Screen, Win 10, MS Office, Ceramic White, 1.24 Kg (13-bb0078TU)', 'Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33.78cm) FHD IPS 400Nits 2-in1 Touch Convertible Laptop (16GB/1TB SSD/Win10/Office/Iris Xe Graphics/Backlit Kb/Black/997gms), 4ZR1D71993', 'Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 14\"(35.56cm) FHD IPS 2-in-1 Touchscreen Laptop(16GB/512GB SSD/Windows 10/MS Office/Lenovo Digital Pen/Fingerprint Reader/Graphite Grey/1.5Kg), 82HS0092IN', 'MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm) FHD IPS-Level 144Hz Panel Laptop (8GB/512GB NVMe SSD/Windows 10 Home/Nvidia GTX1650 4GB GDDR6/Black/2.2Kg), 10SCXR-654IN', 'Lenovo IdeaPad Gaming 3 11th Gen Intel Core i7-11370H 15.6\" (39.63cm) FHD IPS Gaming Laptop (8GB/512GB SSD/Windows 10/NVIDIA RTX 3050 4GB/120Hz Refresh Display/Shadow Black/2.25Kg), 82K1004EIN']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "title=driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]')\n",
    "title1=[]\n",
    "for i in title:\n",
    "    title1.append(i.text)\n",
    "title1=title1[:-17]\n",
    "\n",
    "print(len(title1))\n",
    "\n",
    "print(title1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1,23,350',\n",
       " '95,990',\n",
       " '57,990',\n",
       " '77,990',\n",
       " '85,990',\n",
       " '92,990',\n",
       " '1,07,990',\n",
       " '98,500',\n",
       " '74,990',\n",
       " '84,990']"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "price1=[]\n",
    "for i in price:\n",
    "    price1.append(i.text)\n",
    "price1=price1[:-14]\n",
    "\n",
    "print(len(price1))\n",
    "price1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=driver.find_elements_by_xpath('//span[@class=\"a-icon-alt\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "rating1=[]\n",
    "for i in rating:\n",
    "    \n",
    "    rating1.append(i.text)\n",
    "rating1=rating1[:-19]\n",
    "print(len(rating1))\n",
    "\n",
    "print(rating1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(title1),len(price1),len(rating1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in rating element no text is extracted from the web elements try almost every element from the web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td></td>\n",
       "      <td>1,23,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...</td>\n",
       "      <td></td>\n",
       "      <td>95,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td></td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad S540 11th Gen Intel Core i7 13....</td>\n",
       "      <td></td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td></td>\n",
       "      <td>85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 La...</td>\n",
       "      <td></td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....</td>\n",
       "      <td></td>\n",
       "      <td>1,07,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td></td>\n",
       "      <td>98,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm...</td>\n",
       "      <td></td>\n",
       "      <td>74,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 11th Gen Intel Core i7...</td>\n",
       "      <td></td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating     Price\n",
       "0  HP Envy 11th Gen Core i7 Processor 13.3-inch (...         1,23,350\n",
       "1  ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...           95,990\n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i7-1...           57,990\n",
       "3  Lenovo IdeaPad S540 11th Gen Intel Core i7 13....           77,990\n",
       "4  ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...           85,990\n",
       "5  HP Pavilion 13(2021) 11th Gen Intel Core i7 La...           92,990\n",
       "6  Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....         1,07,990\n",
       "7  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...           98,500\n",
       "8  MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm...           74,990\n",
       "9  Lenovo IdeaPad Gaming 3 11th Gen Intel Core i7...           84,990"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({})\n",
    "df['Title']=title1\n",
    "df['Rating']=rating1\n",
    "df['Price']=price1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
